{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:35:46.019506Z","iopub.execute_input":"2025-01-31T06:35:46.019778Z","iopub.status.idle":"2025-01-31T06:35:49.306557Z","shell.execute_reply.started":"2025-01-31T06:35:46.019733Z","shell.execute_reply":"2025-01-31T06:35:49.305633Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/bert-folder/Cleaned_Nepali_dataset.csv\n/kaggle/input/bert-folder/raw_dataset/raw_dataset/dataset_dict.json\n/kaggle/input/bert-folder/raw_dataset/raw_dataset/validation/state.json\n/kaggle/input/bert-folder/raw_dataset/raw_dataset/validation/dataset_info.json\n/kaggle/input/bert-folder/raw_dataset/raw_dataset/validation/data-00000-of-00001.arrow\n/kaggle/input/bert-folder/raw_dataset/raw_dataset/train/state.json\n/kaggle/input/bert-folder/raw_dataset/raw_dataset/train/dataset_info.json\n/kaggle/input/bert-folder/raw_dataset/raw_dataset/train/data-00000-of-00001.arrow\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install --upgrade pip\n!pip install ipywidgets --upgrade\n!pip install datasets\n!pip install tqdm\n!pip uninstall tensorflow -y\n!pip uninstall keras -y\n!pip install tf-keras  # To satisfy transformers' internal requirement for now\n! pip install optuna","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:35:49.307447Z","iopub.execute_input":"2025-01-31T06:35:49.307912Z","iopub.status.idle":"2025-01-31T06:37:42.600376Z","shell.execute_reply.started":"2025-01-31T06:35:49.307879Z","shell.execute_reply":"2025-01-31T06:37:42.599520Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\nCollecting pip\n  Downloading pip-25.0-py3-none-any.whl.metadata (3.7 kB)\nDownloading pip-25.0-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 24.1.2\n    Uninstalling pip-24.1.2:\n      Successfully uninstalled pip-24.1.2\nSuccessfully installed pip-25.0\nRequirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (8.1.5)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.2)\nRequirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (7.34.0)\nRequirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.7.1)\nRequirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (4.0.13)\nRequirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.13)\nRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (75.1.0)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\nRequirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\nRequirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.13)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\nRequirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\nFound existing installation: tensorflow 2.17.1\nUninstalling tensorflow-2.17.1:\n  Successfully uninstalled tensorflow-2.17.1\nFound existing installation: keras 3.5.0\nUninstalling keras-3.5.0:\n  Successfully uninstalled keras-3.5.0\nRequirement already satisfied: tf-keras in /usr/local/lib/python3.10/dist-packages (2.17.0)\nCollecting tensorflow<2.18,>=2.17 (from tf-keras)\n  Downloading tensorflow-2.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.12.1)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (18.1.1)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.4.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (24.2)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.32.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (75.1.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.5.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.17.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.68.1)\nRequirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.17.1)\nCollecting keras>=3.2.0 (from tensorflow<2.18,>=2.17->tf-keras)\n  Downloading keras-3.8.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.37.1)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.26.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.18,>=2.17->tf-keras) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (13.9.4)\nRequirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (0.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow<2.18,>=2.17->tf-keras) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow<2.18,>=2.17->tf-keras) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow<2.18,>=2.17->tf-keras) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow<2.18,>=2.17->tf-keras) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow<2.18,>=2.17->tf-keras) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow<2.18,>=2.17->tf-keras) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (2024.12.14)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow<2.18,>=2.17->tf-keras) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow<2.18,>=2.17->tf-keras) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0,>=1.23.5->tensorflow<2.18,>=2.17->tf-keras) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.0.0,>=1.23.5->tensorflow<2.18,>=2.17->tf-keras) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (2.18.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.0.0,>=1.23.5->tensorflow<2.18,>=2.17->tf-keras) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (0.1.2)\nDownloading tensorflow-2.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading keras-3.8.0-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: keras, tensorflow\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-3.8.0 tensorflow-2.17.1\nRequirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (4.1.0)\nRequirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.14.0)\nRequirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.9.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\nRequirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.67.1)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\nRequirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.8)\nRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (2.4.1)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->optuna) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->optuna) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->optuna) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->optuna) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->optuna) (2024.2.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## First let's login to huggingface_hub","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:37:42.601282Z","iopub.execute_input":"2025-01-31T06:37:42.601515Z","iopub.status.idle":"2025-01-31T06:37:42.886183Z","shell.execute_reply.started":"2025-01-31T06:37:42.601493Z","shell.execute_reply":"2025-01-31T06:37:42.885249Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ddf2250866b40b6992e02f8d057ebed"}},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## Importing dataset","metadata":{}},{"cell_type":"code","source":"!cp -R /kaggle/input/bert-folder/raw_dataset/raw_dataset /kaggle/working/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:51:11.097777Z","iopub.execute_input":"2025-01-31T06:51:11.098118Z","iopub.status.idle":"2025-01-31T06:51:11.282761Z","shell.execute_reply.started":"2025-01-31T06:51:11.098096Z","shell.execute_reply":"2025-01-31T06:51:11.281669Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"from datasets import Dataset, load_from_disk\n\ndataset = load_from_disk(\"/kaggle/working/raw_dataset\")\n\ntrain = dataset[\"train\"]\nvalidation = dataset[\"validation\"]\n\ntrain = train.rename_column(\"label\", \"labels\")\nvalidation = validation.rename_column(\"label\", \"labels\")\n\nprint(train)\nprint(validation)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:51:42.918600Z","iopub.execute_input":"2025-01-31T06:51:42.918975Z","iopub.status.idle":"2025-01-31T06:51:42.934574Z","shell.execute_reply.started":"2025-01-31T06:51:42.918945Z","shell.execute_reply":"2025-01-31T06:51:42.933948Z"}},"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['text', 'labels'],\n    num_rows: 2287\n})\nDataset({\n    features: ['text', 'labels'],\n    num_rows: 572\n})\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"from collections import Counter\n\nfor k, v in dataset.items():\n    print(k, Counter(dataset[k]['label']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:51:42.937220Z","iopub.execute_input":"2025-01-31T06:51:42.937523Z","iopub.status.idle":"2025-01-31T06:51:42.949669Z","shell.execute_reply.started":"2025-01-31T06:51:42.937459Z","shell.execute_reply":"2025-01-31T06:51:42.948855Z"}},"outputs":[{"name":"stdout","text":"train Counter({0: 1807, 3: 214, 1: 200, 2: 66})\nvalidation Counter({0: 452, 3: 53, 1: 50, 2: 17})\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"import datasets\nimport random\nimport pandas as pd\nfrom IPython.display import display, HTML\n\ndef show_random_elements(dataset, num_examples=10):\n    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n    picks = []\n    for _ in range(num_examples):\n        pick = random.randint(0, len(dataset)-1)\n        while pick in picks:\n            pick = random.randint(0, len(dataset)-1)\n        picks.append(pick)\n    \n    df = pd.DataFrame(dataset[picks])\n    for column, typ in dataset.features.items():\n        if isinstance(typ, datasets.ClassLabel):\n            df[column] = df[column].transform(lambda i: typ.names[i])\n    display(HTML(df.to_html()))\n\nshow_random_elements(dataset[\"train\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:51:42.964247Z","iopub.execute_input":"2025-01-31T06:51:42.964438Z","iopub.status.idle":"2025-01-31T06:51:42.974485Z","shell.execute_reply.started":"2025-01-31T06:51:42.964421Z","shell.execute_reply":"2025-01-31T06:51:42.973837Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>भ्रष्टचारी घुसखोरी कानुन दायरा लिएर राम धुलाई गर्दा कसो होला मेयर ज्यु ।</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>जाहा सरकार , प्रहरी प्रसाशन , अदालत न्याय पाउँदैन भनेर बुझे ।</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>रास्ट्रपति गरिमामय पद व्यक्ति बिपक्षी दल नेता एउ टा दल नेता हैसियत खिल्ली मजाक उडाए देख्दा रास्ट्रपति सम्मानित पद बेज्जत अपमान ।</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>भ्रष्टाचार अन्त्य मेयरजी हरु यता हाजिर गरमत ️ ️ ।</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>रवि एउटा व्याक्ति होइन सिङ्गो नेपाली आशा धरोहर ।</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>मानवअधिकार वाद नाम कंलक भनौदी कालो मोसो दलेर सडक नघुमाइ नहुने भयो थुक्क कुकुर्नी जता डलर पायो उतै सरल्क तै न्याय यहि ।</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3 जना माहा पुरुष ठिक मन्त्री ज्यु प्रष्ट बुज्न सकिन्छ पद पाटी बचाउदै छिन ।</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ऋषि धमाला चाहिँ भ्रष्ट दलाल चोर नेता हरु चम्चे ।</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>रवि बाघ जना झोले कुकुर हरु भुक्दै ।</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>न्युज भन्दापनि सुरुकाे 5 मिनेट दिएकाे दम्दार प्रस्तुति चाहिँ गजब लाग्छ ... ।</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}],"execution_count":28},{"cell_type":"markdown","source":"# Preprocessing and Tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\n\nmodel_name= \"Sakonii/distilbert-base-nepali\"\n\ntokenizer= AutoTokenizer.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:51:42.992310Z","iopub.execute_input":"2025-01-31T06:51:42.992527Z","iopub.status.idle":"2025-01-31T06:51:43.234380Z","shell.execute_reply.started":"2025-01-31T06:51:42.992508Z","shell.execute_reply":"2025-01-31T06:51:43.233654Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# Generating Embeddings\ndef preprocess_function(document):\n    return tokenizer(document[\"text\"], truncation=True, padding='max_length')\n\ntrain_tokenized= train.map(preprocess_function, batched= False,remove_columns=[\"text\"])\nvalidation_tokenized= validation.map(preprocess_function, batched= False,remove_columns=[\"text\"])\n\n# Convert to DataFrame and reorder columns\ntrain2 = pd.DataFrame(train_tokenized)\ntrain2 = train2[['input_ids', 'attention_mask', 'labels']]  # Set the correct order\n\n# Convert back to Dataset\ntrain_tokenized = Dataset.from_pandas(train2)\ntrain_tokenized = train_tokenized.with_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n\nvalidation2 = pd.DataFrame(validation_tokenized)\nvalidation2 = validation2[['input_ids', 'attention_mask', 'labels']]  # Set the correct order\n\n# Convert back to Dataset\nvalidation_tokenized = Dataset.from_pandas(validation2)\nvalidation_tokenized = validation_tokenized.with_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n\n\n\nprint(validation_tokenized.features.keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:51:43.235575Z","iopub.execute_input":"2025-01-31T06:51:43.235840Z","iopub.status.idle":"2025-01-31T06:51:46.079234Z","shell.execute_reply.started":"2025-01-31T06:51:43.235820Z","shell.execute_reply":"2025-01-31T06:51:46.078332Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2287 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f2fd8f605384b57ae5136a6341d610d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/572 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57abb4653ad243c2b11953691ea8be04"}},"metadata":{}},{"name":"stdout","text":"dict_keys(['input_ids', 'attention_mask', 'labels'])\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"import os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:51:46.080889Z","iopub.execute_input":"2025-01-31T06:51:46.081125Z","iopub.status.idle":"2025-01-31T06:51:46.084441Z","shell.execute_reply.started":"2025-01-31T06:51:46.081105Z","shell.execute_reply":"2025-01-31T06:51:46.083806Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"# Hyperparamter Search","metadata":{}},{"cell_type":"markdown","source":"## Compute metrics","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n\n    report = classification_report(y_true=labels, y_pred=predictions, output_dict=True)\n\n    accuracy = report['accuracy']\n    recall = report['macro avg']['recall']\n    precision = report['macro avg']['precision']\n    f1 = report['macro avg']['f1-score']\n    return {\n        \"accuracy\": accuracy,\n        \"recall\": recall,\n        \"precision\": precision,\n        \"f1\": f1\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:51:46.085405Z","iopub.execute_input":"2025-01-31T06:51:46.085676Z","iopub.status.idle":"2025-01-31T06:51:46.109401Z","shell.execute_reply.started":"2025-01-31T06:51:46.085655Z","shell.execute_reply":"2025-01-31T06:51:46.108703Z"}},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":"## Custom Loss function with class weights","metadata":{}},{"cell_type":"code","source":"from torch import nn\nimport torch\nfrom sklearn.utils.class_weight import compute_class_weight\n\n# Number of classes\nnum_labels = 4\n\n# The labels in Train dataset\nlabels = train[\"labels\"]\n\n# obtaining class weight with compute_class_weight\nclass_weights = compute_class_weight(\n        class_weight=\"balanced\",\n        classes=np.unique(labels),\n        y=labels\n    )\nclass_weights = class_weights / np.sum(class_weights)  # Normalizing magnitude for proper gradient updates\n\n# Convert class weights to a PyTorch tensor\nclass_weights = torch.tensor(class_weights, dtype=torch.float32)\nprint(class_weights)\n\n# Custom loss function\ndef compute_loss_func(outputs, labels, num_items_in_batch=None):\n    logits = outputs.logits\n    weights = class_weights.to(logits.device)\n    loss_fct = nn.CrossEntropyLoss(weight=weights)\n    loss = loss_fct(logits.view(-1, num_labels), labels.view(-1))\n    return loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:55:02.928066Z","iopub.execute_input":"2025-01-31T06:55:02.928442Z","iopub.status.idle":"2025-01-31T06:55:03.054450Z","shell.execute_reply.started":"2025-01-31T06:55:02.928415Z","shell.execute_reply":"2025-01-31T06:55:03.053564Z"}},"outputs":[{"name":"stdout","text":"tensor([0.0218, 0.1970, 0.5970, 0.1841])\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"## Wandb for logging","metadata":{}},{"cell_type":"code","source":"# wandb for logging, get the login key from wandb.ai/authorize\n!pip install wandb\nimport wandb\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\nwandb_secret = user_secrets.get_secret(\"wandb\")\nwandb.login(key=wandb_secret)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:55:32.708619Z","iopub.execute_input":"2025-01-31T06:55:32.708988Z","iopub.status.idle":"2025-01-31T06:55:42.619415Z","shell.execute_reply.started":"2025-01-31T06:55:32.708959Z","shell.execute_reply":"2025-01-31T06:55:42.618519Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.19.1)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.10.3)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.12.14)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtamangangel2057\u001b[0m (\u001b[33mtamangangel2057-student\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":36},{"cell_type":"markdown","source":"## Training Arguments and Trainer","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\nfrom transformers import EarlyStoppingCallback\n\noutput_dir = \"/kaggle/working/BERT_Classifier_v2\"\nrun_name= \"BERT_v2\"\n\nargs = TrainingArguments(\n    output_dir=output_dir,\n    run_name=run_name,\n    eval_strategy=\"epoch\",\n    per_device_train_batch_size=4, # Each device takes this batch, so 2 T4 GPU each take 4 making 8\n    per_device_eval_batch_size=8,\n    gradient_accumulation_steps=2,\n    warmup_ratio= 0.1,\n    save_strategy=\"epoch\",\n    save_on_each_node=True,\n    learning_rate=1e-5,\n    num_train_epochs=20,\n    weight_decay=0.01,\n    report_to=\"wandb\",\n    push_to_hub=False,\n    save_total_limit= 1,\n    metric_for_best_model = 'f1',\n    load_best_model_at_end=True,\n    greater_is_better=True,\n    overwrite_output_dir= True,\n    bf16=True,\n)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:55:42.620601Z","iopub.execute_input":"2025-01-31T06:55:42.621204Z","iopub.status.idle":"2025-01-31T06:55:42.654505Z","shell.execute_reply.started":"2025-01-31T06:55:42.621175Z","shell.execute_reply":"2025-01-31T06:55:42.653895Z"}},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":"## Model Initilization","metadata":{}},{"cell_type":"code","source":"# To perform hyperparameter search the model should be initialized inside a function\ndef model_init():\n   return AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:57:18.535108Z","iopub.execute_input":"2025-01-31T06:57:18.535403Z","iopub.status.idle":"2025-01-31T06:57:18.539084Z","shell.execute_reply.started":"2025-01-31T06:57:18.535382Z","shell.execute_reply":"2025-01-31T06:57:18.538327Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"# Initialize the Trainer\n\ntrainer = Trainer(\n    model_init=model_init,\n    args=args,\n    train_dataset=train_tokenized,\n    eval_dataset=validation_tokenized,\n    compute_metrics=compute_metrics,\n    compute_loss_func=compute_loss_func, # Loss function with weights\n    callbacks = [EarlyStoppingCallback(early_stopping_patience=5, early_stopping_threshold=0.005,)]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:58:38.231248Z","iopub.execute_input":"2025-01-31T06:58:38.231738Z","iopub.status.idle":"2025-01-31T06:58:38.427862Z","shell.execute_reply.started":"2025-01-31T06:58:38.231686Z","shell.execute_reply":"2025-01-31T06:58:38.427011Z"}},"outputs":[{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":45},{"cell_type":"markdown","source":"## Perform Hyperparameter search","metadata":{}},{"cell_type":"code","source":"!pip install bitsandbytes # For adamw_bnb_8bit\n!pip install lion-pytorch # For lion_32bit","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:58:46.930276Z","iopub.execute_input":"2025-01-31T06:58:46.930593Z","iopub.status.idle":"2025-01-31T06:58:56.357557Z","shell.execute_reply.started":"2025-01-31T06:58:46.930566Z","shell.execute_reply":"2025-01-31T06:58:56.356682Z"}},"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\nRequirement already satisfied: torch~=2.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->bitsandbytes) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->bitsandbytes) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->bitsandbytes) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->bitsandbytes) (2024.9.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch~=2.0->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch~=2.0->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nDownloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m113.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.45.1\nCollecting lion-pytorch\n  Downloading lion_pytorch-0.2.3-py3-none-any.whl.metadata (616 bytes)\nRequirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from lion-pytorch) (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->lion-pytorch) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->lion-pytorch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->lion-pytorch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->lion-pytorch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->lion-pytorch) (2024.9.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->lion-pytorch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.6->lion-pytorch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->lion-pytorch) (3.0.2)\nDownloading lion_pytorch-0.2.3-py3-none-any.whl (6.6 kB)\nInstalling collected packages: lion-pytorch\nSuccessfully installed lion-pytorch-0.2.3\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"def compute_objective(metrics):\n    return metrics[\"f1\"]\n\ndef optuna_hp_space(trial):\n    # Suggest the optimizer first\n    optimizer = trial.suggest_categorical(\"optimizer\", [\"adamw_torch\", \"adafactor\", \"sgd\", \"adamw_bnb_8bit\", \"lion_32bit\"])\n    \n    # Hyperparameter space\n    hp_space = {\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True),\n        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [4, 8, 16]),\n        \"per_device_eval_batch_size\": trial.suggest_categorical(\"eval_batch_size\", [8, 16, 32]),\n        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.001, 0.1),\n        \"warmup_ratio\": trial.suggest_float(\"warmup_ratio\", 0.05, 0.3),\n        \"gradient_accumulation_steps\": trial.suggest_categorical(\"grad_acc_steps\", [1, 2, 4]),\n        \"optim\": optimizer,\n    }\n    \n    # Add momentum only if the optimizer is 'sgd'\n    if optimizer == \"sgd\":\n        hp_space[\"momentum\"] = trial.suggest_float(\"momentum\", 0.8, 0.99)\n    \n    return hp_space","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T07:02:47.742122Z","iopub.execute_input":"2025-01-31T07:02:47.742434Z","iopub.status.idle":"2025-01-31T07:02:47.748563Z","shell.execute_reply.started":"2025-01-31T07:02:47.742413Z","shell.execute_reply":"2025-01-31T07:02:47.747828Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"best_trials = trainer.hyperparameter_search(\n    direction=[\"maximize\"],\n    backend=\"optuna\",\n    hp_space=optuna_hp_space,\n    n_trials=30,\n    compute_objective=compute_objective,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T07:02:53.128577Z","iopub.execute_input":"2025-01-31T07:02:53.128894Z","iopub.status.idle":"2025-01-31T09:34:44.651142Z","shell.execute_reply.started":"2025-01-31T07:02:53.128871Z","shell.execute_reply":"2025-01-31T09:34:44.650298Z"}},"outputs":[{"name":"stderr","text":"[I 2025-01-31 07:02:53,130] A new study created in memory with name: no-name-c5f2319c-8ef8-4f0c-86b5-dde7e0451a17\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_070254-5vug2jfz</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/5vug2jfz' target=\"_blank\">daily-moon-18</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/5vug2jfz' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/5vug2jfz</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='198' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [198/360 11:37 < 09:36, 0.28 it/s, Epoch 11/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.369070</td>\n      <td>0.365385</td>\n      <td>0.315747</td>\n      <td>0.303637</td>\n      <td>0.189424</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.365133</td>\n      <td>0.444056</td>\n      <td>0.328711</td>\n      <td>0.314234</td>\n      <td>0.231838</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>1.356933</td>\n      <td>0.601399</td>\n      <td>0.363249</td>\n      <td>0.337335</td>\n      <td>0.308605</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>1.350240</td>\n      <td>0.669580</td>\n      <td>0.352358</td>\n      <td>0.329209</td>\n      <td>0.328587</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>1.342977</td>\n      <td>0.697552</td>\n      <td>0.366786</td>\n      <td>0.334579</td>\n      <td>0.347007</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>1.334798</td>\n      <td>0.706294</td>\n      <td>0.391503</td>\n      <td>0.348918</td>\n      <td>0.365445</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>No log</td>\n      <td>1.327596</td>\n      <td>0.692308</td>\n      <td>0.387361</td>\n      <td>0.338321</td>\n      <td>0.354775</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>No log</td>\n      <td>1.321629</td>\n      <td>0.666084</td>\n      <td>0.387393</td>\n      <td>0.331039</td>\n      <td>0.346082</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>No log</td>\n      <td>1.314158</td>\n      <td>0.687063</td>\n      <td>0.377091</td>\n      <td>0.334500</td>\n      <td>0.346714</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>No log</td>\n      <td>1.308839</td>\n      <td>0.676573</td>\n      <td>0.408499</td>\n      <td>0.349209</td>\n      <td>0.361812</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>No log</td>\n      <td>1.303443</td>\n      <td>0.674825</td>\n      <td>0.411827</td>\n      <td>0.347684</td>\n      <td>0.363118</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n[I 2025-01-31 07:14:43,894] Trial 0 finished with value: 0.36311790621266427 and parameters: {'optimizer': 'lion_32bit', 'learning_rate': 1.9655890690045967e-05, 'per_device_train_batch_size': 16, 'eval_batch_size': 8, 'weight_decay': 0.09805869347808056, 'warmup_ratio': 0.13210259721151663, 'grad_acc_steps': 4}. Best is trial 0 with value: 0.36311790621266427.\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▃▆▇███▇█▇▇</td></tr><tr><td>eval/f1</td><td>▁▃▆▇▇██▇▇██</td></tr><tr><td>eval/loss</td><td>██▇▆▅▄▄▃▂▂▁</td></tr><tr><td>eval/precision</td><td>▁▃▆▅▆█▆▅▆██</td></tr><tr><td>eval/recall</td><td>▁▂▄▄▅▇▆▆▅██</td></tr><tr><td>eval/runtime</td><td>█▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▇▇▇▇▇████▇</td></tr><tr><td>eval/steps_per_second</td><td>▁▇▇▇▇▇████▇</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▄▅▅▆▇▇██</td></tr><tr><td>train/global_step</td><td>▁▂▂▃▄▅▅▆▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.67483</td></tr><tr><td>eval/f1</td><td>0.36312</td></tr><tr><td>eval/loss</td><td>1.30344</td></tr><tr><td>eval/precision</td><td>0.34768</td></tr><tr><td>eval/recall</td><td>0.41183</td></tr><tr><td>eval/runtime</td><td>5.0828</td></tr><tr><td>eval/samples_per_second</td><td>112.535</td></tr><tr><td>eval/steps_per_second</td><td>7.083</td></tr><tr><td>total_flos</td><td>3332601208172544.0</td></tr><tr><td>train/epoch</td><td>11</td></tr><tr><td>train/global_step</td><td>198</td></tr><tr><td>train_loss</td><td>1.35675</td></tr><tr><td>train_runtime</td><td>709.6231</td></tr><tr><td>train_samples_per_second</td><td>64.457</td></tr><tr><td>train_steps_per_second</td><td>0.507</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">daily-moon-18</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/5vug2jfz' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/5vug2jfz</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_070254-5vug2jfz/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_071446-7860by0r</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/7860by0r' target=\"_blank\">leafy-water-19</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/7860by0r' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/7860by0r</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='576' max='1440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 576/1440 08:40 < 13:03, 1.10 it/s, Epoch 8/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.339185</td>\n      <td>0.758741</td>\n      <td>0.302018</td>\n      <td>0.299425</td>\n      <td>0.287831</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.908469</td>\n      <td>0.692308</td>\n      <td>0.677709</td>\n      <td>0.475178</td>\n      <td>0.511866</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.952799</td>\n      <td>0.781469</td>\n      <td>0.680621</td>\n      <td>0.573578</td>\n      <td>0.614208</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.958751</td>\n      <td>0.723776</td>\n      <td>0.686860</td>\n      <td>0.539304</td>\n      <td>0.578681</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>1.136083</td>\n      <td>0.730769</td>\n      <td>0.615732</td>\n      <td>0.507166</td>\n      <td>0.545729</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>1.424930</td>\n      <td>0.727273</td>\n      <td>0.605486</td>\n      <td>0.511320</td>\n      <td>0.542487</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.721400</td>\n      <td>1.762230</td>\n      <td>0.737762</td>\n      <td>0.568253</td>\n      <td>0.501068</td>\n      <td>0.527142</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.721400</td>\n      <td>1.779676</td>\n      <td>0.739510</td>\n      <td>0.579361</td>\n      <td>0.522501</td>\n      <td>0.542995</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n[I 2025-01-31 07:23:33,916] Trial 1 finished with value: 0.5429948239735435 and parameters: {'optimizer': 'adafactor', 'learning_rate': 4.845088714034207e-05, 'per_device_train_batch_size': 16, 'eval_batch_size': 32, 'weight_decay': 0.032952986010699674, 'warmup_ratio': 0.06046338586454088, 'grad_acc_steps': 1}. Best is trial 1 with value: 0.5429948239735435.\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▆▁█▃▄▄▅▅</td></tr><tr><td>eval/f1</td><td>▁▆█▇▇▆▆▆</td></tr><tr><td>eval/loss</td><td>▄▁▁▁▃▅██</td></tr><tr><td>eval/precision</td><td>▁▅█▇▆▆▆▇</td></tr><tr><td>eval/recall</td><td>▁███▇▇▆▆</td></tr><tr><td>eval/runtime</td><td>▁▅▆▆▄█▇▆</td></tr><tr><td>eval/samples_per_second</td><td>█▄▃▃▅▁▂▃</td></tr><tr><td>eval/steps_per_second</td><td>█▄▃▃▅▁▂▃</td></tr><tr><td>train/epoch</td><td>▁▂▃▄▅▆▇▇██</td></tr><tr><td>train/global_step</td><td>▁▂▃▄▅▆▇▇██</td></tr><tr><td>train/grad_norm</td><td>▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.73951</td></tr><tr><td>eval/f1</td><td>0.54299</td></tr><tr><td>eval/loss</td><td>1.77968</td></tr><tr><td>eval/precision</td><td>0.5225</td></tr><tr><td>eval/recall</td><td>0.57936</td></tr><tr><td>eval/runtime</td><td>4.9569</td></tr><tr><td>eval/samples_per_second</td><td>115.395</td></tr><tr><td>eval/steps_per_second</td><td>1.816</td></tr><tr><td>total_flos</td><td>2423709969580032.0</td></tr><tr><td>train/epoch</td><td>8</td></tr><tr><td>train/global_step</td><td>576</td></tr><tr><td>train/grad_norm</td><td>3.27208</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/loss</td><td>0.7214</td></tr><tr><td>train_loss</td><td>0.66415</td></tr><tr><td>train_runtime</td><td>529.1463</td></tr><tr><td>train_samples_per_second</td><td>86.441</td></tr><tr><td>train_steps_per_second</td><td>2.721</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">leafy-water-19</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/7860by0r' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/7860by0r</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_071446-7860by0r/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_072335-duaq15sq</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/duaq15sq' target=\"_blank\">summer-wind-20</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/duaq15sq' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/duaq15sq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2574' max='5720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2574/5720 11:45 < 14:23, 3.64 it/s, Epoch 9/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.385483</td>\n      <td>0.788462</td>\n      <td>0.267235</td>\n      <td>0.282887</td>\n      <td>0.253108</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.294500</td>\n      <td>1.147804</td>\n      <td>0.629371</td>\n      <td>0.483837</td>\n      <td>0.369585</td>\n      <td>0.377770</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.294500</td>\n      <td>1.186592</td>\n      <td>0.741259</td>\n      <td>0.542983</td>\n      <td>0.584108</td>\n      <td>0.516521</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.958700</td>\n      <td>0.947835</td>\n      <td>0.756993</td>\n      <td>0.699872</td>\n      <td>0.577942</td>\n      <td>0.615282</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.958700</td>\n      <td>1.097518</td>\n      <td>0.734266</td>\n      <td>0.687102</td>\n      <td>0.547635</td>\n      <td>0.591845</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.718900</td>\n      <td>1.411223</td>\n      <td>0.743007</td>\n      <td>0.592393</td>\n      <td>0.519095</td>\n      <td>0.547474</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.556400</td>\n      <td>1.862595</td>\n      <td>0.750000</td>\n      <td>0.541033</td>\n      <td>0.514223</td>\n      <td>0.524684</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.556400</td>\n      <td>1.871112</td>\n      <td>0.736014</td>\n      <td>0.575186</td>\n      <td>0.498411</td>\n      <td>0.527263</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.404100</td>\n      <td>2.060758</td>\n      <td>0.704545</td>\n      <td>0.523338</td>\n      <td>0.497189</td>\n      <td>0.497808</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n[I 2025-01-31 07:35:28,155] Trial 2 finished with value: 0.4978075569826956 and parameters: {'optimizer': 'adamw_bnb_8bit', 'learning_rate': 1.9165942005355648e-05, 'per_device_train_batch_size': 4, 'eval_batch_size': 32, 'weight_decay': 0.09172868307357833, 'warmup_ratio': 0.17707559519779958, 'grad_acc_steps': 1}. Best is trial 1 with value: 0.5429948239735435.\nTrying to set momentum in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>█▁▆▇▆▆▆▆▄</td></tr><tr><td>eval/f1</td><td>▁▃▆██▇▆▆▆</td></tr><tr><td>eval/loss</td><td>▄▂▃▁▂▄▇▇█</td></tr><tr><td>eval/precision</td><td>▁▃██▇▆▆▆▆</td></tr><tr><td>eval/recall</td><td>▁▅▅██▆▅▆▅</td></tr><tr><td>eval/runtime</td><td>▁▅█▇▇▆▆▅▇</td></tr><tr><td>eval/samples_per_second</td><td>█▄▁▂▂▃▃▄▂</td></tr><tr><td>eval/steps_per_second</td><td>█▄▁▂▂▃▃▄▂</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▃▄▅▅▅▆▆▇███</td></tr><tr><td>train/global_step</td><td>▁▂▂▃▃▄▅▅▅▆▆▇███</td></tr><tr><td>train/grad_norm</td><td>▁█▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁█▇▅▄</td></tr><tr><td>train/loss</td><td>█▅▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.70455</td></tr><tr><td>eval/f1</td><td>0.49781</td></tr><tr><td>eval/loss</td><td>2.06076</td></tr><tr><td>eval/precision</td><td>0.49719</td></tr><tr><td>eval/recall</td><td>0.52334</td></tr><tr><td>eval/runtime</td><td>4.9345</td></tr><tr><td>eval/samples_per_second</td><td>115.918</td></tr><tr><td>eval/steps_per_second</td><td>1.824</td></tr><tr><td>total_flos</td><td>2726673715777536.0</td></tr><tr><td>train/epoch</td><td>9</td></tr><tr><td>train/global_step</td><td>2574</td></tr><tr><td>train/grad_norm</td><td>0.4878</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.4041</td></tr><tr><td>train_loss</td><td>0.77664</td></tr><tr><td>train_runtime</td><td>713.4153</td></tr><tr><td>train_samples_per_second</td><td>64.114</td></tr><tr><td>train_steps_per_second</td><td>8.018</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">summer-wind-20</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/duaq15sq' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/duaq15sq</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_072335-duaq15sq/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_073530-pwq5gk00</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/pwq5gk00' target=\"_blank\">swept-bush-21</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/pwq5gk00' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/pwq5gk00</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='432' max='1420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 432/1420 06:37 < 15:14, 1.08 it/s, Epoch 6/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.377584</td>\n      <td>0.312937</td>\n      <td>0.303318</td>\n      <td>0.322208</td>\n      <td>0.168242</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.377581</td>\n      <td>0.312937</td>\n      <td>0.303318</td>\n      <td>0.322208</td>\n      <td>0.168242</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>1.377576</td>\n      <td>0.312937</td>\n      <td>0.303318</td>\n      <td>0.322208</td>\n      <td>0.168242</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>1.377567</td>\n      <td>0.314685</td>\n      <td>0.303871</td>\n      <td>0.322538</td>\n      <td>0.169000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>1.377558</td>\n      <td>0.314685</td>\n      <td>0.303871</td>\n      <td>0.322538</td>\n      <td>0.169000</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>1.377545</td>\n      <td>0.314685</td>\n      <td>0.303871</td>\n      <td>0.322538</td>\n      <td>0.169000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"[I 2025-01-31 07:42:15,339] Trial 3 finished with value: 0.16900007855379512 and parameters: {'optimizer': 'sgd', 'learning_rate': 3.6771973170261352e-06, 'per_device_train_batch_size': 8, 'eval_batch_size': 32, 'weight_decay': 0.0742167937834179, 'warmup_ratio': 0.2765540689715989, 'grad_acc_steps': 2, 'momentum': 0.8452434544272568}. Best is trial 1 with value: 0.5429948239735435.\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▁███</td></tr><tr><td>eval/f1</td><td>▁▁▁███</td></tr><tr><td>eval/loss</td><td>█▇▇▅▃▁</td></tr><tr><td>eval/precision</td><td>▁▁▁███</td></tr><tr><td>eval/recall</td><td>▁▁▁███</td></tr><tr><td>eval/runtime</td><td>▁█▆▅█▄</td></tr><tr><td>eval/samples_per_second</td><td>█▁▃▄▁▅</td></tr><tr><td>eval/steps_per_second</td><td>█▁▃▄▁▅</td></tr><tr><td>train/epoch</td><td>▁▂▄▅▇██</td></tr><tr><td>train/global_step</td><td>▁▂▄▅▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.31469</td></tr><tr><td>eval/f1</td><td>0.169</td></tr><tr><td>eval/loss</td><td>1.37754</td></tr><tr><td>eval/precision</td><td>0.32254</td></tr><tr><td>eval/recall</td><td>0.30387</td></tr><tr><td>eval/runtime</td><td>4.9265</td></tr><tr><td>eval/samples_per_second</td><td>116.107</td></tr><tr><td>eval/steps_per_second</td><td>1.827</td></tr><tr><td>total_flos</td><td>1817782477185024.0</td></tr><tr><td>train/epoch</td><td>6</td></tr><tr><td>train/global_step</td><td>432</td></tr><tr><td>train_loss</td><td>1.3723</td></tr><tr><td>train_runtime</td><td>406.3878</td></tr><tr><td>train_samples_per_second</td><td>112.553</td></tr><tr><td>train_steps_per_second</td><td>3.494</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">swept-bush-21</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/pwq5gk00' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/pwq5gk00</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_073530-pwq5gk00/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_074217-8yfc9n29</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/8yfc9n29' target=\"_blank\">elated-water-22</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/8yfc9n29' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/8yfc9n29</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2860' max='5720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2860/5720 13:26 < 13:27, 3.54 it/s, Epoch 10/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.385913</td>\n      <td>0.790210</td>\n      <td>0.250000</td>\n      <td>0.197552</td>\n      <td>0.220703</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.331300</td>\n      <td>1.317478</td>\n      <td>0.610140</td>\n      <td>0.411898</td>\n      <td>0.330648</td>\n      <td>0.338194</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.331300</td>\n      <td>1.230300</td>\n      <td>0.673077</td>\n      <td>0.420935</td>\n      <td>0.362494</td>\n      <td>0.361506</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.130600</td>\n      <td>1.046617</td>\n      <td>0.685315</td>\n      <td>0.490423</td>\n      <td>0.526579</td>\n      <td>0.431040</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.130600</td>\n      <td>0.929512</td>\n      <td>0.736014</td>\n      <td>0.641845</td>\n      <td>0.538528</td>\n      <td>0.572207</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.845100</td>\n      <td>0.937260</td>\n      <td>0.727273</td>\n      <td>0.654611</td>\n      <td>0.519707</td>\n      <td>0.564067</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.619800</td>\n      <td>1.376052</td>\n      <td>0.770979</td>\n      <td>0.578479</td>\n      <td>0.537218</td>\n      <td>0.555398</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.619800</td>\n      <td>1.334057</td>\n      <td>0.760490</td>\n      <td>0.625134</td>\n      <td>0.535840</td>\n      <td>0.571131</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.458300</td>\n      <td>1.672333</td>\n      <td>0.762238</td>\n      <td>0.585985</td>\n      <td>0.535691</td>\n      <td>0.557028</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.458300</td>\n      <td>1.981157</td>\n      <td>0.756993</td>\n      <td>0.541555</td>\n      <td>0.519639</td>\n      <td>0.528743</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n[I 2025-01-31 07:55:51,009] Trial 4 finished with value: 0.5287428378896121 and parameters: {'optimizer': 'adamw_torch', 'learning_rate': 9.174302271740983e-06, 'per_device_train_batch_size': 4, 'eval_batch_size': 32, 'weight_decay': 0.044185666058543044, 'warmup_ratio': 0.20216403123641247, 'grad_acc_steps': 1}. Best is trial 1 with value: 0.5429948239735435.\nTrying to set momentum in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>█▁▃▄▆▆▇▇▇▇</td></tr><tr><td>eval/f1</td><td>▁▃▄▅█████▇</td></tr><tr><td>eval/loss</td><td>▄▄▃▂▁▁▄▄▆█</td></tr><tr><td>eval/precision</td><td>▁▄▄███████</td></tr><tr><td>eval/recall</td><td>▁▄▄▅██▇▇▇▆</td></tr><tr><td>eval/runtime</td><td>▁▅▅▅▇▅█▇█▆</td></tr><tr><td>eval/samples_per_second</td><td>█▄▄▄▂▄▁▂▁▃</td></tr><tr><td>eval/steps_per_second</td><td>█▄▄▄▂▄▁▂▁▃</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▃▃▄▄▅▆▆▆▇▇██</td></tr><tr><td>train/global_step</td><td>▁▂▂▃▃▃▄▄▅▆▆▆▇▇██</td></tr><tr><td>train/grad_norm</td><td>▂▂▃█▁</td></tr><tr><td>train/learning_rate</td><td>▁▇█▆▅</td></tr><tr><td>train/loss</td><td>█▆▄▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.75699</td></tr><tr><td>eval/f1</td><td>0.52874</td></tr><tr><td>eval/loss</td><td>1.98116</td></tr><tr><td>eval/precision</td><td>0.51964</td></tr><tr><td>eval/recall</td><td>0.54156</td></tr><tr><td>eval/runtime</td><td>4.9416</td></tr><tr><td>eval/samples_per_second</td><td>115.751</td></tr><tr><td>eval/steps_per_second</td><td>1.821</td></tr><tr><td>total_flos</td><td>3029637461975040.0</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>2860</td></tr><tr><td>train/grad_norm</td><td>3.08723</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.4583</td></tr><tr><td>train_loss</td><td>0.81734</td></tr><tr><td>train_runtime</td><td>814.7938</td></tr><tr><td>train_samples_per_second</td><td>56.137</td></tr><tr><td>train_steps_per_second</td><td>7.02</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">elated-water-22</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/8yfc9n29' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/8yfc9n29</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_074217-8yfc9n29/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_075553-qebt7txu</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/qebt7txu' target=\"_blank\">exalted-sun-23</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/qebt7txu' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/qebt7txu</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='286' max='5720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 286/5720 01:14 < 23:41, 3.82 it/s, Epoch 1/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.377558</td>\n      <td>0.318182</td>\n      <td>0.304977</td>\n      <td>0.323188</td>\n      <td>0.170511</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"[I 2025-01-31 07:57:13,789] Trial 5 pruned. \nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.31818</td></tr><tr><td>eval/f1</td><td>0.17051</td></tr><tr><td>eval/loss</td><td>1.37756</td></tr><tr><td>eval/precision</td><td>0.32319</td></tr><tr><td>eval/recall</td><td>0.30498</td></tr><tr><td>eval/runtime</td><td>4.8149</td></tr><tr><td>eval/samples_per_second</td><td>118.797</td></tr><tr><td>eval/steps_per_second</td><td>1.869</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>286</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">exalted-sun-23</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/qebt7txu' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/qebt7txu</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_075553-qebt7txu/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_075715-j7of0f46</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/j7of0f46' target=\"_blank\">vivid-violet-24</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/j7of0f46' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/j7of0f46</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='324' max='700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [324/700 10:08 < 11:50, 0.53 it/s, Epoch 9/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.349524</td>\n      <td>0.791958</td>\n      <td>0.272505</td>\n      <td>0.449288</td>\n      <td>0.264481</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.160361</td>\n      <td>0.648601</td>\n      <td>0.513393</td>\n      <td>0.490626</td>\n      <td>0.473199</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.927265</td>\n      <td>0.711538</td>\n      <td>0.684322</td>\n      <td>0.508691</td>\n      <td>0.557136</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.856436</td>\n      <td>0.748252</td>\n      <td>0.687363</td>\n      <td>0.548391</td>\n      <td>0.595170</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.834175</td>\n      <td>0.662587</td>\n      <td>0.691919</td>\n      <td>0.521777</td>\n      <td>0.557679</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>0.934818</td>\n      <td>0.729021</td>\n      <td>0.655447</td>\n      <td>0.537377</td>\n      <td>0.575141</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>No log</td>\n      <td>1.090591</td>\n      <td>0.730769</td>\n      <td>0.613542</td>\n      <td>0.534484</td>\n      <td>0.556313</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>No log</td>\n      <td>1.085297</td>\n      <td>0.723776</td>\n      <td>0.607411</td>\n      <td>0.502338</td>\n      <td>0.536812</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>No log</td>\n      <td>1.328026</td>\n      <td>0.741259</td>\n      <td>0.569359</td>\n      <td>0.506014</td>\n      <td>0.530331</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n[I 2025-01-31 08:07:32,235] Trial 6 finished with value: 0.530331337720651 and parameters: {'optimizer': 'adamw_torch', 'learning_rate': 2.663804912263604e-05, 'per_device_train_batch_size': 8, 'eval_batch_size': 16, 'weight_decay': 0.0396242290099031, 'warmup_ratio': 0.0839698308211864, 'grad_acc_steps': 4}. Best is trial 1 with value: 0.5429948239735435.\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>█▁▄▆▂▅▅▅▆</td></tr><tr><td>eval/f1</td><td>▁▅▇█▇█▇▇▇</td></tr><tr><td>eval/loss</td><td>█▅▂▁▁▂▄▄█</td></tr><tr><td>eval/precision</td><td>▁▄▅█▆▇▇▅▅</td></tr><tr><td>eval/recall</td><td>▁▅███▇▇▇▆</td></tr><tr><td>eval/runtime</td><td>▁▇▇▇▇▆█▇▇</td></tr><tr><td>eval/samples_per_second</td><td>█▂▂▁▂▃▁▂▂</td></tr><tr><td>eval/steps_per_second</td><td>█▂▂▂▂▃▁▂▂</td></tr><tr><td>train/epoch</td><td>▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/global_step</td><td>▁▂▃▄▅▅▆▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.74126</td></tr><tr><td>eval/f1</td><td>0.53033</td></tr><tr><td>eval/loss</td><td>1.32803</td></tr><tr><td>eval/precision</td><td>0.50601</td></tr><tr><td>eval/recall</td><td>0.56936</td></tr><tr><td>eval/runtime</td><td>5.0756</td></tr><tr><td>eval/samples_per_second</td><td>112.695</td></tr><tr><td>eval/steps_per_second</td><td>3.546</td></tr><tr><td>total_flos</td><td>3029637461975040.0</td></tr><tr><td>train/epoch</td><td>9</td></tr><tr><td>train/global_step</td><td>324</td></tr><tr><td>train_loss</td><td>0.73762</td></tr><tr><td>train_runtime</td><td>617.6606</td></tr><tr><td>train_samples_per_second</td><td>74.054</td></tr><tr><td>train_steps_per_second</td><td>1.133</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">vivid-violet-24</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/j7of0f46' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/j7of0f46</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_075715-j7of0f46/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_080734-0tokjemh</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/0tokjemh' target=\"_blank\">effortless-frost-25</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/0tokjemh' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/0tokjemh</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='72' max='1440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  72/1440 01:02 < 20:30, 1.11 it/s, Epoch 1/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.355035</td>\n      <td>0.611888</td>\n      <td>0.350195</td>\n      <td>0.323990</td>\n      <td>0.307912</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n[I 2025-01-31 08:08:44,154] Trial 7 pruned. \nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.61189</td></tr><tr><td>eval/f1</td><td>0.30791</td></tr><tr><td>eval/loss</td><td>1.35503</td></tr><tr><td>eval/precision</td><td>0.32399</td></tr><tr><td>eval/recall</td><td>0.35019</td></tr><tr><td>eval/runtime</td><td>5.0682</td></tr><tr><td>eval/samples_per_second</td><td>112.862</td></tr><tr><td>eval/steps_per_second</td><td>7.103</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>72</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">effortless-frost-25</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/0tokjemh' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/0tokjemh</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_080734-0tokjemh/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_080846-jhwzlzmg</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/jhwzlzmg' target=\"_blank\">prime-sponge-26</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/jhwzlzmg' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/jhwzlzmg</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='72' max='1420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  72/1420 01:06 < 21:22, 1.05 it/s, Epoch 1/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.365749</td>\n      <td>0.431818</td>\n      <td>0.315945</td>\n      <td>0.326286</td>\n      <td>0.211817</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"[I 2025-01-31 08:09:59,862] Trial 8 pruned. \nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.43182</td></tr><tr><td>eval/f1</td><td>0.21182</td></tr><tr><td>eval/loss</td><td>1.36575</td></tr><tr><td>eval/precision</td><td>0.32629</td></tr><tr><td>eval/recall</td><td>0.31595</td></tr><tr><td>eval/runtime</td><td>5.0973</td></tr><tr><td>eval/samples_per_second</td><td>112.216</td></tr><tr><td>eval/steps_per_second</td><td>7.063</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>72</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">prime-sponge-26</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/jhwzlzmg' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/jhwzlzmg</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_080846-jhwzlzmg/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_081001-d0ok4pjs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/d0ok4pjs' target=\"_blank\">fanciful-firefly-27</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/d0ok4pjs' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/d0ok4pjs</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='72' max='1420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  72/1420 01:13 < 23:31, 0.95 it/s, Epoch 1/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.385741</td>\n      <td>0.790210</td>\n      <td>0.250000</td>\n      <td>0.197552</td>\n      <td>0.220703</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n[I 2025-01-31 08:11:22,560] Trial 9 pruned. \nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.79021</td></tr><tr><td>eval/f1</td><td>0.2207</td></tr><tr><td>eval/loss</td><td>1.38574</td></tr><tr><td>eval/precision</td><td>0.19755</td></tr><tr><td>eval/recall</td><td>0.25</td></tr><tr><td>eval/runtime</td><td>4.8732</td></tr><tr><td>eval/samples_per_second</td><td>117.378</td></tr><tr><td>eval/steps_per_second</td><td>1.847</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>72</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">fanciful-firefly-27</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/d0ok4pjs' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/d0ok4pjs</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_081001-d0ok4pjs/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_081124-nqce737r</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/nqce737r' target=\"_blank\">rosy-thunder-28</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/nqce737r' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/nqce737r</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='576' max='1440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 576/1440 08:41 < 13:04, 1.10 it/s, Epoch 8/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.157615</td>\n      <td>0.547203</td>\n      <td>0.554989</td>\n      <td>0.508169</td>\n      <td>0.409370</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.926373</td>\n      <td>0.713287</td>\n      <td>0.663527</td>\n      <td>0.487613</td>\n      <td>0.521245</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>1.022470</td>\n      <td>0.751748</td>\n      <td>0.614354</td>\n      <td>0.578572</td>\n      <td>0.580204</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>1.140894</td>\n      <td>0.715035</td>\n      <td>0.646895</td>\n      <td>0.502010</td>\n      <td>0.539136</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>1.152967</td>\n      <td>0.716783</td>\n      <td>0.643247</td>\n      <td>0.525066</td>\n      <td>0.563350</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>1.376852</td>\n      <td>0.716783</td>\n      <td>0.610495</td>\n      <td>0.507667</td>\n      <td>0.541796</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.711800</td>\n      <td>1.791616</td>\n      <td>0.739510</td>\n      <td>0.595451</td>\n      <td>0.523243</td>\n      <td>0.550767</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.711800</td>\n      <td>1.825951</td>\n      <td>0.704545</td>\n      <td>0.571368</td>\n      <td>0.512304</td>\n      <td>0.527616</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"[I 2025-01-31 08:20:12,904] Trial 10 finished with value: 0.5276156591946066 and parameters: {'optimizer': 'adafactor', 'learning_rate': 9.238791846369779e-05, 'per_device_train_batch_size': 16, 'eval_batch_size': 16, 'weight_decay': 0.008955774745835005, 'warmup_ratio': 0.05477703231816697, 'grad_acc_steps': 1}. Best is trial 1 with value: 0.5429948239735435.\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇█▇▇▇█▆</td></tr><tr><td>eval/f1</td><td>▁▆█▆▇▆▇▆</td></tr><tr><td>eval/loss</td><td>▃▁▂▃▃▅██</td></tr><tr><td>eval/precision</td><td>▃▁█▂▄▃▄▃</td></tr><tr><td>eval/recall</td><td>▁█▅▇▇▅▄▂</td></tr><tr><td>eval/runtime</td><td>▁█▆▆▆▆▆▃</td></tr><tr><td>eval/samples_per_second</td><td>█▁▃▃▃▃▃▆</td></tr><tr><td>eval/steps_per_second</td><td>█▁▃▃▃▃▃▆</td></tr><tr><td>train/epoch</td><td>▁▂▃▄▅▆▇▇██</td></tr><tr><td>train/global_step</td><td>▁▂▃▄▅▆▇▇██</td></tr><tr><td>train/grad_norm</td><td>▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.70455</td></tr><tr><td>eval/f1</td><td>0.52762</td></tr><tr><td>eval/loss</td><td>1.82595</td></tr><tr><td>eval/precision</td><td>0.5123</td></tr><tr><td>eval/recall</td><td>0.57137</td></tr><tr><td>eval/runtime</td><td>5.0388</td></tr><tr><td>eval/samples_per_second</td><td>113.519</td></tr><tr><td>eval/steps_per_second</td><td>3.572</td></tr><tr><td>total_flos</td><td>3332601208172544.0</td></tr><tr><td>train/epoch</td><td>8</td></tr><tr><td>train/global_step</td><td>576</td></tr><tr><td>train/grad_norm</td><td>17.69237</td></tr><tr><td>train/learning_rate</td><td>6e-05</td></tr><tr><td>train/loss</td><td>0.7118</td></tr><tr><td>train_loss</td><td>0.66021</td></tr><tr><td>train_runtime</td><td>529.6239</td></tr><tr><td>train_samples_per_second</td><td>86.363</td></tr><tr><td>train_steps_per_second</td><td>2.719</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">rosy-thunder-28</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/nqce737r' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/nqce737r</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_081124-nqce737r/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_082014-agkpcfqk</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/agkpcfqk' target=\"_blank\">wobbly-water-29</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/agkpcfqk' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/agkpcfqk</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='324' max='700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [324/700 10:03 < 11:44, 0.53 it/s, Epoch 9/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.322320</td>\n      <td>0.814685</td>\n      <td>0.401282</td>\n      <td>0.610713</td>\n      <td>0.445867</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.897465</td>\n      <td>0.652098</td>\n      <td>0.669188</td>\n      <td>0.455039</td>\n      <td>0.489993</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.801175</td>\n      <td>0.645105</td>\n      <td>0.715818</td>\n      <td>0.519982</td>\n      <td>0.556811</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>1.096480</td>\n      <td>0.755245</td>\n      <td>0.673769</td>\n      <td>0.570446</td>\n      <td>0.603761</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>1.387416</td>\n      <td>0.736014</td>\n      <td>0.596818</td>\n      <td>0.509037</td>\n      <td>0.543488</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>1.687852</td>\n      <td>0.743007</td>\n      <td>0.571857</td>\n      <td>0.513717</td>\n      <td>0.537311</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>No log</td>\n      <td>1.675046</td>\n      <td>0.737762</td>\n      <td>0.564938</td>\n      <td>0.515654</td>\n      <td>0.534288</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>No log</td>\n      <td>1.537342</td>\n      <td>0.713287</td>\n      <td>0.588852</td>\n      <td>0.509841</td>\n      <td>0.533946</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>No log</td>\n      <td>1.893230</td>\n      <td>0.713287</td>\n      <td>0.545515</td>\n      <td>0.483994</td>\n      <td>0.506528</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n[I 2025-01-31 08:30:26,327] Trial 11 finished with value: 0.5065275986543566 and parameters: {'optimizer': 'adafactor', 'learning_rate': 9.706473542439114e-05, 'per_device_train_batch_size': 8, 'eval_batch_size': 16, 'weight_decay': 0.024395928811130656, 'warmup_ratio': 0.0535972676712996, 'grad_acc_steps': 4}. Best is trial 1 with value: 0.5429948239735435.\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>█▁▁▆▅▅▅▄▄</td></tr><tr><td>eval/f1</td><td>▁▃▆█▅▅▅▅▄</td></tr><tr><td>eval/loss</td><td>▄▂▁▃▅▇▇▆█</td></tr><tr><td>eval/precision</td><td>█▁▄▆▃▄▄▃▂</td></tr><tr><td>eval/recall</td><td>▁▇█▇▅▅▅▅▄</td></tr><tr><td>eval/runtime</td><td>▁█▇▇█▇▇██</td></tr><tr><td>eval/samples_per_second</td><td>█▁▂▂▁▂▂▁▁</td></tr><tr><td>eval/steps_per_second</td><td>█▁▂▁▁▂▂▁▁</td></tr><tr><td>train/epoch</td><td>▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/global_step</td><td>▁▂▃▄▅▅▆▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.71329</td></tr><tr><td>eval/f1</td><td>0.50653</td></tr><tr><td>eval/loss</td><td>1.89323</td></tr><tr><td>eval/precision</td><td>0.48399</td></tr><tr><td>eval/recall</td><td>0.54552</td></tr><tr><td>eval/runtime</td><td>5.0763</td></tr><tr><td>eval/samples_per_second</td><td>112.68</td></tr><tr><td>eval/steps_per_second</td><td>3.546</td></tr><tr><td>total_flos</td><td>2726673715777536.0</td></tr><tr><td>train/epoch</td><td>9</td></tr><tr><td>train/global_step</td><td>324</td></tr><tr><td>train_loss</td><td>0.61369</td></tr><tr><td>train_runtime</td><td>612.6454</td></tr><tr><td>train_samples_per_second</td><td>74.66</td></tr><tr><td>train_steps_per_second</td><td>1.143</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">wobbly-water-29</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/agkpcfqk' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/agkpcfqk</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_082014-agkpcfqk/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_083028-lt5ed66u</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/lt5ed66u' target=\"_blank\">pious-snowball-30</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/lt5ed66u' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/lt5ed66u</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='162' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [162/360 09:31 < 11:46, 0.28 it/s, Epoch 9/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.355405</td>\n      <td>0.657343</td>\n      <td>0.343554</td>\n      <td>0.303771</td>\n      <td>0.310410</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.267595</td>\n      <td>0.498252</td>\n      <td>0.604426</td>\n      <td>0.403187</td>\n      <td>0.398808</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>1.114374</td>\n      <td>0.452797</td>\n      <td>0.605033</td>\n      <td>0.492125</td>\n      <td>0.435059</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.942364</td>\n      <td>0.774476</td>\n      <td>0.641529</td>\n      <td>0.571529</td>\n      <td>0.591559</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.896249</td>\n      <td>0.762238</td>\n      <td>0.655930</td>\n      <td>0.553538</td>\n      <td>0.591402</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>0.853537</td>\n      <td>0.687063</td>\n      <td>0.685226</td>\n      <td>0.515681</td>\n      <td>0.558221</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>No log</td>\n      <td>1.064398</td>\n      <td>0.767483</td>\n      <td>0.632889</td>\n      <td>0.527235</td>\n      <td>0.565326</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>No log</td>\n      <td>1.026074</td>\n      <td>0.699301</td>\n      <td>0.607750</td>\n      <td>0.525825</td>\n      <td>0.542733</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>No log</td>\n      <td>1.077916</td>\n      <td>0.720280</td>\n      <td>0.603802</td>\n      <td>0.494889</td>\n      <td>0.532134</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"[I 2025-01-31 08:40:09,121] Trial 12 finished with value: 0.5321335491623497 and parameters: {'optimizer': 'adafactor', 'learning_rate': 4.1129945164404356e-05, 'per_device_train_batch_size': 16, 'eval_batch_size': 16, 'weight_decay': 0.021687108250932084, 'warmup_ratio': 0.13425175343472923, 'grad_acc_steps': 4}. Best is trial 1 with value: 0.5429948239735435.\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▅▂▁██▆█▆▇</td></tr><tr><td>eval/f1</td><td>▁▃▄██▇▇▇▇</td></tr><tr><td>eval/loss</td><td>█▇▅▂▂▁▄▃▄</td></tr><tr><td>eval/precision</td><td>▁▄▆██▇▇▇▆</td></tr><tr><td>eval/recall</td><td>▁▆▆▇▇█▇▆▆</td></tr><tr><td>eval/runtime</td><td>▁██▆▇▆▇▆▇</td></tr><tr><td>eval/samples_per_second</td><td>█▁▁▃▂▃▂▃▂</td></tr><tr><td>eval/steps_per_second</td><td>█▁▂▃▂▃▂▃▂</td></tr><tr><td>train/epoch</td><td>▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/global_step</td><td>▁▂▃▄▅▅▆▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.72028</td></tr><tr><td>eval/f1</td><td>0.53213</td></tr><tr><td>eval/loss</td><td>1.07792</td></tr><tr><td>eval/precision</td><td>0.49489</td></tr><tr><td>eval/recall</td><td>0.6038</td></tr><tr><td>eval/runtime</td><td>5.0739</td></tr><tr><td>eval/samples_per_second</td><td>112.734</td></tr><tr><td>eval/steps_per_second</td><td>3.548</td></tr><tr><td>total_flos</td><td>2726673715777536.0</td></tr><tr><td>train/epoch</td><td>9</td></tr><tr><td>train/global_step</td><td>162</td></tr><tr><td>train_loss</td><td>0.82839</td></tr><tr><td>train_runtime</td><td>582.046</td></tr><tr><td>train_samples_per_second</td><td>78.585</td></tr><tr><td>train_steps_per_second</td><td>0.619</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">pious-snowball-30</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/lt5ed66u' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/lt5ed66u</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_083028-lt5ed66u/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_084011-s5i3zwhz</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/s5i3zwhz' target=\"_blank\">distinctive-field-31</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/s5i3zwhz' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/s5i3zwhz</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='108' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [108/360 06:18 < 15:00, 0.28 it/s, Epoch 6/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.351235</td>\n      <td>0.655594</td>\n      <td>0.339403</td>\n      <td>0.306559</td>\n      <td>0.298656</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.246676</td>\n      <td>0.482517</td>\n      <td>0.609371</td>\n      <td>0.393398</td>\n      <td>0.369008</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>1.060950</td>\n      <td>0.472028</td>\n      <td>0.633031</td>\n      <td>0.491258</td>\n      <td>0.451929</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.888204</td>\n      <td>0.515734</td>\n      <td>0.669920</td>\n      <td>0.474172</td>\n      <td>0.464653</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.841921</td>\n      <td>0.697552</td>\n      <td>0.673506</td>\n      <td>0.507667</td>\n      <td>0.550599</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>0.876514</td>\n      <td>0.650350</td>\n      <td>0.697224</td>\n      <td>0.512269</td>\n      <td>0.547224</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n[I 2025-01-31 08:46:39,267] Trial 13 pruned. \nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▇▁▁▂█▇</td></tr><tr><td>eval/f1</td><td>▁▃▅▆██</td></tr><tr><td>eval/loss</td><td>█▇▄▂▁▁</td></tr><tr><td>eval/precision</td><td>▁▄▇▇██</td></tr><tr><td>eval/recall</td><td>▁▆▇▇██</td></tr><tr><td>eval/runtime</td><td>▃█▁▆▆▆</td></tr><tr><td>eval/samples_per_second</td><td>▆▁█▃▃▃</td></tr><tr><td>eval/steps_per_second</td><td>▆▁█▃▃▃</td></tr><tr><td>train/epoch</td><td>▁▂▄▅▇█</td></tr><tr><td>train/global_step</td><td>▁▂▄▅▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.65035</td></tr><tr><td>eval/f1</td><td>0.54722</td></tr><tr><td>eval/loss</td><td>0.87651</td></tr><tr><td>eval/precision</td><td>0.51227</td></tr><tr><td>eval/recall</td><td>0.69722</td></tr><tr><td>eval/runtime</td><td>5.0682</td></tr><tr><td>eval/samples_per_second</td><td>112.86</td></tr><tr><td>eval/steps_per_second</td><td>3.552</td></tr><tr><td>train/epoch</td><td>6</td></tr><tr><td>train/global_step</td><td>108</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">distinctive-field-31</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/s5i3zwhz' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/s5i3zwhz</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_084011-s5i3zwhz/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_084641-txvypsfo</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/txvypsfo' target=\"_blank\">cerulean-jazz-32</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/txvypsfo' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/txvypsfo</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='36' max='720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 36/720 01:02 < 20:50, 0.55 it/s, Epoch 1/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.374348</td>\n      <td>0.330420</td>\n      <td>0.304685</td>\n      <td>0.303100</td>\n      <td>0.175259</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"[I 2025-01-31 08:47:51,338] Trial 14 pruned. \nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.33042</td></tr><tr><td>eval/f1</td><td>0.17526</td></tr><tr><td>eval/loss</td><td>1.37435</td></tr><tr><td>eval/precision</td><td>0.3031</td></tr><tr><td>eval/recall</td><td>0.30468</td></tr><tr><td>eval/runtime</td><td>4.993</td></tr><tr><td>eval/samples_per_second</td><td>114.559</td></tr><tr><td>eval/steps_per_second</td><td>3.605</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>36</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">cerulean-jazz-32</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/txvypsfo' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/txvypsfo</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_084641-txvypsfo/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_084753-pl7ic6ei</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/pl7ic6ei' target=\"_blank\">worthy-wave-33</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/pl7ic6ei' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/pl7ic6ei</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='72' max='1440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  72/1440 01:04 < 20:52, 1.09 it/s, Epoch 1/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.361403</td>\n      <td>0.604895</td>\n      <td>0.379394</td>\n      <td>0.320836</td>\n      <td>0.324966</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n[I 2025-01-31 08:49:04,444] Trial 15 pruned. \nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.6049</td></tr><tr><td>eval/f1</td><td>0.32497</td></tr><tr><td>eval/loss</td><td>1.3614</td></tr><tr><td>eval/precision</td><td>0.32084</td></tr><tr><td>eval/recall</td><td>0.37939</td></tr><tr><td>eval/runtime</td><td>4.9256</td></tr><tr><td>eval/samples_per_second</td><td>116.127</td></tr><tr><td>eval/steps_per_second</td><td>1.827</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>72</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">worthy-wave-33</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/pl7ic6ei' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/pl7ic6ei</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_084753-pl7ic6ei/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_084906-r2qg7z2l</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/r2qg7z2l' target=\"_blank\">sweet-plant-34</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/r2qg7z2l' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/r2qg7z2l</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='108' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [108/360 06:17 < 14:57, 0.28 it/s, Epoch 6/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.338733</td>\n      <td>0.704545</td>\n      <td>0.423978</td>\n      <td>0.368721</td>\n      <td>0.383873</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.154204</td>\n      <td>0.652098</td>\n      <td>0.595252</td>\n      <td>0.450257</td>\n      <td>0.477345</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.906850</td>\n      <td>0.615385</td>\n      <td>0.653865</td>\n      <td>0.454357</td>\n      <td>0.465117</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.841127</td>\n      <td>0.718531</td>\n      <td>0.666281</td>\n      <td>0.507307</td>\n      <td>0.553235</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.874472</td>\n      <td>0.702797</td>\n      <td>0.682726</td>\n      <td>0.513988</td>\n      <td>0.555443</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>0.983555</td>\n      <td>0.720280</td>\n      <td>0.632950</td>\n      <td>0.518797</td>\n      <td>0.554046</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n[I 2025-01-31 08:55:33,394] Trial 16 pruned. \nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▇▃▁█▇█</td></tr><tr><td>eval/f1</td><td>▁▅▄███</td></tr><tr><td>eval/loss</td><td>█▅▂▁▁▃</td></tr><tr><td>eval/precision</td><td>▁▅▅▇██</td></tr><tr><td>eval/recall</td><td>▁▆▇██▇</td></tr><tr><td>eval/runtime</td><td>▁▇▅▆▆█</td></tr><tr><td>eval/samples_per_second</td><td>█▂▄▃▃▁</td></tr><tr><td>eval/steps_per_second</td><td>█▂▄▃▃▁</td></tr><tr><td>train/epoch</td><td>▁▂▄▅▇█</td></tr><tr><td>train/global_step</td><td>▁▂▄▅▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.72028</td></tr><tr><td>eval/f1</td><td>0.55405</td></tr><tr><td>eval/loss</td><td>0.98356</td></tr><tr><td>eval/precision</td><td>0.5188</td></tr><tr><td>eval/recall</td><td>0.63295</td></tr><tr><td>eval/runtime</td><td>5.0764</td></tr><tr><td>eval/samples_per_second</td><td>112.678</td></tr><tr><td>eval/steps_per_second</td><td>3.546</td></tr><tr><td>train/epoch</td><td>6</td></tr><tr><td>train/global_step</td><td>108</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">sweet-plant-34</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/r2qg7z2l' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/r2qg7z2l</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_084906-r2qg7z2l/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_085535-0zauj6tk</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/0zauj6tk' target=\"_blank\">happy-terrain-35</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/0zauj6tk' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/0zauj6tk</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='18' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 18/360 00:59 < 21:20, 0.27 it/s, Epoch 1/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.372558</td>\n      <td>0.400350</td>\n      <td>0.314600</td>\n      <td>0.324629</td>\n      <td>0.209122</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"[I 2025-01-31 08:56:44,765] Trial 17 pruned. \nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.40035</td></tr><tr><td>eval/f1</td><td>0.20912</td></tr><tr><td>eval/loss</td><td>1.37256</td></tr><tr><td>eval/precision</td><td>0.32463</td></tr><tr><td>eval/recall</td><td>0.3146</td></tr><tr><td>eval/runtime</td><td>4.9722</td></tr><tr><td>eval/samples_per_second</td><td>115.041</td></tr><tr><td>eval/steps_per_second</td><td>3.62</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>18</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">happy-terrain-35</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/0zauj6tk' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/0zauj6tk</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_085535-0zauj6tk/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_085646-40bfkv6u</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/40bfkv6u' target=\"_blank\">distinctive-jazz-36</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/40bfkv6u' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/40bfkv6u</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='72' max='1440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  72/1440 01:03 < 20:50, 1.09 it/s, Epoch 1/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.332923</td>\n      <td>0.583916</td>\n      <td>0.340093</td>\n      <td>0.295302</td>\n      <td>0.258986</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n[I 2025-01-31 08:57:57,766] Trial 18 pruned. \nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.58392</td></tr><tr><td>eval/f1</td><td>0.25899</td></tr><tr><td>eval/loss</td><td>1.33292</td></tr><tr><td>eval/precision</td><td>0.2953</td></tr><tr><td>eval/recall</td><td>0.34009</td></tr><tr><td>eval/runtime</td><td>4.8452</td></tr><tr><td>eval/samples_per_second</td><td>118.056</td></tr><tr><td>eval/steps_per_second</td><td>1.858</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>72</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">distinctive-jazz-36</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/40bfkv6u' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/40bfkv6u</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_085646-40bfkv6u/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_085759-jb4217pk</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/jb4217pk' target=\"_blank\">grateful-thunder-37</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/jb4217pk' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/jb4217pk</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='36' max='720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 36/720 01:02 < 20:54, 0.55 it/s, Epoch 1/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.368855</td>\n      <td>0.344406</td>\n      <td>0.313557</td>\n      <td>0.324968</td>\n      <td>0.189047</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"[I 2025-01-31 08:59:10,024] Trial 19 pruned. \nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.34441</td></tr><tr><td>eval/f1</td><td>0.18905</td></tr><tr><td>eval/loss</td><td>1.36886</td></tr><tr><td>eval/precision</td><td>0.32497</td></tr><tr><td>eval/recall</td><td>0.31356</td></tr><tr><td>eval/runtime</td><td>5.0594</td></tr><tr><td>eval/samples_per_second</td><td>113.056</td></tr><tr><td>eval/steps_per_second</td><td>7.115</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>36</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">grateful-thunder-37</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/jb4217pk' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/jb4217pk</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_085759-jb4217pk/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_085911-qwm8tu73</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/qwm8tu73' target=\"_blank\">crisp-jazz-38</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/qwm8tu73' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/qwm8tu73</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='180' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [180/360 10:33 < 10:40, 0.28 it/s, Epoch 10/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.359608</td>\n      <td>0.573427</td>\n      <td>0.378817</td>\n      <td>0.343988</td>\n      <td>0.297117</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.285558</td>\n      <td>0.622378</td>\n      <td>0.462712</td>\n      <td>0.428254</td>\n      <td>0.398323</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>1.109339</td>\n      <td>0.613636</td>\n      <td>0.605036</td>\n      <td>0.433408</td>\n      <td>0.463159</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.941878</td>\n      <td>0.673077</td>\n      <td>0.662738</td>\n      <td>0.473061</td>\n      <td>0.508953</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.833513</td>\n      <td>0.716783</td>\n      <td>0.693787</td>\n      <td>0.529377</td>\n      <td>0.575901</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>0.802950</td>\n      <td>0.694056</td>\n      <td>0.684333</td>\n      <td>0.485653</td>\n      <td>0.535459</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>No log</td>\n      <td>0.953528</td>\n      <td>0.699301</td>\n      <td>0.636621</td>\n      <td>0.524780</td>\n      <td>0.554031</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>No log</td>\n      <td>1.036209</td>\n      <td>0.720280</td>\n      <td>0.620741</td>\n      <td>0.516017</td>\n      <td>0.549891</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>No log</td>\n      <td>1.223279</td>\n      <td>0.743007</td>\n      <td>0.579052</td>\n      <td>0.522149</td>\n      <td>0.543836</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>No log</td>\n      <td>1.123449</td>\n      <td>0.722028</td>\n      <td>0.607424</td>\n      <td>0.517972</td>\n      <td>0.546524</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n[I 2025-01-31 09:09:54,537] Trial 20 finished with value: 0.5465236447783807 and parameters: {'optimizer': 'adamw_bnb_8bit', 'learning_rate': 3.069428769798208e-05, 'per_device_train_batch_size': 16, 'eval_batch_size': 32, 'weight_decay': 0.03234878918376074, 'warmup_ratio': 0.12690580927347275, 'grad_acc_steps': 4}. Best is trial 20 with value: 0.5465236447783807.\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▃▃▅▇▆▆▇█▇</td></tr><tr><td>eval/f1</td><td>▁▄▅▆█▇▇▇▇▇</td></tr><tr><td>eval/loss</td><td>█▇▅▃▁▁▃▄▆▅</td></tr><tr><td>eval/precision</td><td>▁▄▄▆█▆█▇██</td></tr><tr><td>eval/recall</td><td>▁▃▆▇██▇▆▅▆</td></tr><tr><td>eval/runtime</td><td>▁█▇▅▅▆▅▄▅▅</td></tr><tr><td>eval/samples_per_second</td><td>█▁▂▄▄▃▄▅▄▄</td></tr><tr><td>eval/steps_per_second</td><td>█▁▂▄▄▃▄▄▄▄</td></tr><tr><td>train/epoch</td><td>▁▂▃▃▄▅▆▆▇██</td></tr><tr><td>train/global_step</td><td>▁▂▃▃▄▅▆▆▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.72203</td></tr><tr><td>eval/f1</td><td>0.54652</td></tr><tr><td>eval/loss</td><td>1.12345</td></tr><tr><td>eval/precision</td><td>0.51797</td></tr><tr><td>eval/recall</td><td>0.60742</td></tr><tr><td>eval/runtime</td><td>4.9577</td></tr><tr><td>eval/samples_per_second</td><td>115.377</td></tr><tr><td>eval/steps_per_second</td><td>1.815</td></tr><tr><td>total_flos</td><td>8180021147332608.0</td></tr><tr><td>train/epoch</td><td>10</td></tr><tr><td>train/global_step</td><td>180</td></tr><tr><td>train_loss</td><td>0.79474</td></tr><tr><td>train_runtime</td><td>643.7307</td></tr><tr><td>train_samples_per_second</td><td>71.055</td></tr><tr><td>train_steps_per_second</td><td>0.559</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">crisp-jazz-38</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/qwm8tu73' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/qwm8tu73</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_085911-qwm8tu73/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_091006-ynk9x424</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/ynk9x424' target=\"_blank\">stellar-surf-39</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/ynk9x424' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/ynk9x424</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='18' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 18/360 01:00 < 21:27, 0.27 it/s, Epoch 1/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.360992</td>\n      <td>0.566434</td>\n      <td>0.376604</td>\n      <td>0.351308</td>\n      <td>0.295313</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n[I 2025-01-31 09:11:16,151] Trial 21 pruned. \nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.56643</td></tr><tr><td>eval/f1</td><td>0.29531</td></tr><tr><td>eval/loss</td><td>1.36099</td></tr><tr><td>eval/precision</td><td>0.35131</td></tr><tr><td>eval/recall</td><td>0.3766</td></tr><tr><td>eval/runtime</td><td>4.9402</td></tr><tr><td>eval/samples_per_second</td><td>115.786</td></tr><tr><td>eval/steps_per_second</td><td>1.822</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>18</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">stellar-surf-39</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/ynk9x424' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/ynk9x424</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_091006-ynk9x424/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_091119-ffj2n4dt</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/ffj2n4dt' target=\"_blank\">lively-puddle-40</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/ffj2n4dt' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/ffj2n4dt</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='18' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 18/360 01:00 < 21:26, 0.27 it/s, Epoch 1/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.367472</td>\n      <td>0.477273</td>\n      <td>0.351994</td>\n      <td>0.396828</td>\n      <td>0.254820</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"[I 2025-01-31 09:12:29,511] Trial 22 pruned. \nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.47727</td></tr><tr><td>eval/f1</td><td>0.25482</td></tr><tr><td>eval/loss</td><td>1.36747</td></tr><tr><td>eval/precision</td><td>0.39683</td></tr><tr><td>eval/recall</td><td>0.35199</td></tr><tr><td>eval/runtime</td><td>4.9696</td></tr><tr><td>eval/samples_per_second</td><td>115.1</td></tr><tr><td>eval/steps_per_second</td><td>1.811</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>18</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">lively-puddle-40</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/ffj2n4dt' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/ffj2n4dt</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_091119-ffj2n4dt/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_091231-nedpsnvp</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/nedpsnvp' target=\"_blank\">zesty-frog-41</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/nedpsnvp' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/nedpsnvp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='90' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 90/360 05:14 < 16:04, 0.28 it/s, Epoch 5/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.337427</td>\n      <td>0.715035</td>\n      <td>0.414805</td>\n      <td>0.363781</td>\n      <td>0.380835</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.149035</td>\n      <td>0.664336</td>\n      <td>0.590513</td>\n      <td>0.459139</td>\n      <td>0.479403</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.935517</td>\n      <td>0.631119</td>\n      <td>0.663289</td>\n      <td>0.457651</td>\n      <td>0.474202</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.837448</td>\n      <td>0.720280</td>\n      <td>0.685717</td>\n      <td>0.513179</td>\n      <td>0.560194</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.828857</td>\n      <td>0.683566</td>\n      <td>0.664679</td>\n      <td>0.496938</td>\n      <td>0.536661</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n[I 2025-01-31 09:17:55,424] Trial 23 pruned. \nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>█▄▁█▅</td></tr><tr><td>eval/f1</td><td>▁▅▅█▇</td></tr><tr><td>eval/loss</td><td>█▅▂▁▁</td></tr><tr><td>eval/precision</td><td>▁▅▅█▇</td></tr><tr><td>eval/recall</td><td>▁▆▇█▇</td></tr><tr><td>eval/runtime</td><td>▁█▁█▆</td></tr><tr><td>eval/samples_per_second</td><td>█▁█▁▃</td></tr><tr><td>eval/steps_per_second</td><td>█▁█▁▃</td></tr><tr><td>train/epoch</td><td>▁▃▅▆█</td></tr><tr><td>train/global_step</td><td>▁▃▅▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.68357</td></tr><tr><td>eval/f1</td><td>0.53666</td></tr><tr><td>eval/loss</td><td>0.82886</td></tr><tr><td>eval/precision</td><td>0.49694</td></tr><tr><td>eval/recall</td><td>0.66468</td></tr><tr><td>eval/runtime</td><td>4.9796</td></tr><tr><td>eval/samples_per_second</td><td>114.87</td></tr><tr><td>eval/steps_per_second</td><td>1.807</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>90</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">zesty-frog-41</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/nedpsnvp' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/nedpsnvp</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_091231-nedpsnvp/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_091757-lba53kf6</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/lba53kf6' target=\"_blank\">swift-totem-42</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/lba53kf6' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/lba53kf6</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='18' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 18/360 00:59 < 21:21, 0.27 it/s, Epoch 1/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.368430</td>\n      <td>0.618881</td>\n      <td>0.326575</td>\n      <td>0.309892</td>\n      <td>0.292098</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"[I 2025-01-31 09:19:07,235] Trial 24 pruned. \nTrying to set momentum in the hyperparameter search but there is no corresponding field in `TrainingArguments`.\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.61888</td></tr><tr><td>eval/f1</td><td>0.2921</td></tr><tr><td>eval/loss</td><td>1.36843</td></tr><tr><td>eval/precision</td><td>0.30989</td></tr><tr><td>eval/recall</td><td>0.32657</td></tr><tr><td>eval/runtime</td><td>4.9398</td></tr><tr><td>eval/samples_per_second</td><td>115.795</td></tr><tr><td>eval/steps_per_second</td><td>1.822</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>18</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">swift-totem-42</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/lba53kf6' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/lba53kf6</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_091757-lba53kf6/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_091909-iec8e6vn</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/iec8e6vn' target=\"_blank\">rural-yogurt-43</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/iec8e6vn' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/iec8e6vn</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='72' max='1440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  72/1440 01:02 < 20:24, 1.12 it/s, Epoch 1/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.375404</td>\n      <td>0.312937</td>\n      <td>0.303318</td>\n      <td>0.322208</td>\n      <td>0.168242</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"[I 2025-01-31 09:20:18,803] Trial 25 pruned. \nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.31294</td></tr><tr><td>eval/f1</td><td>0.16824</td></tr><tr><td>eval/loss</td><td>1.3754</td></tr><tr><td>eval/precision</td><td>0.32221</td></tr><tr><td>eval/recall</td><td>0.30332</td></tr><tr><td>eval/runtime</td><td>5.0629</td></tr><tr><td>eval/samples_per_second</td><td>112.98</td></tr><tr><td>eval/steps_per_second</td><td>3.555</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>72</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">rural-yogurt-43</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/iec8e6vn' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/iec8e6vn</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_091909-iec8e6vn/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_092021-4xf9gwxd</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/4xf9gwxd' target=\"_blank\">robust-puddle-44</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/4xf9gwxd' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/4xf9gwxd</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='90' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 90/360 05:14 < 16:03, 0.28 it/s, Epoch 5/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.358446</td>\n      <td>0.589161</td>\n      <td>0.379631</td>\n      <td>0.337598</td>\n      <td>0.301280</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.280439</td>\n      <td>0.587413</td>\n      <td>0.493297</td>\n      <td>0.433776</td>\n      <td>0.415022</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>1.081669</td>\n      <td>0.617133</td>\n      <td>0.631125</td>\n      <td>0.449460</td>\n      <td>0.477019</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.869957</td>\n      <td>0.685315</td>\n      <td>0.679102</td>\n      <td>0.499702</td>\n      <td>0.541961</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.832693</td>\n      <td>0.671329</td>\n      <td>0.703578</td>\n      <td>0.521875</td>\n      <td>0.562530</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n[I 2025-01-31 09:25:44,726] Trial 26 pruned. \nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▃█▇</td></tr><tr><td>eval/f1</td><td>▁▄▆▇█</td></tr><tr><td>eval/loss</td><td>█▇▄▁▁</td></tr><tr><td>eval/precision</td><td>▁▅▅▇█</td></tr><tr><td>eval/recall</td><td>▁▃▆▇█</td></tr><tr><td>eval/runtime</td><td>▄█▄▅▁</td></tr><tr><td>eval/samples_per_second</td><td>▅▁▅▄█</td></tr><tr><td>eval/steps_per_second</td><td>▅▁▅▅█</td></tr><tr><td>train/epoch</td><td>▁▃▅▆█</td></tr><tr><td>train/global_step</td><td>▁▃▅▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.67133</td></tr><tr><td>eval/f1</td><td>0.56253</td></tr><tr><td>eval/loss</td><td>0.83269</td></tr><tr><td>eval/precision</td><td>0.52188</td></tr><tr><td>eval/recall</td><td>0.70358</td></tr><tr><td>eval/runtime</td><td>4.9337</td></tr><tr><td>eval/samples_per_second</td><td>115.938</td></tr><tr><td>eval/steps_per_second</td><td>1.824</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>90</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">robust-puddle-44</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/4xf9gwxd' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/4xf9gwxd</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_092021-4xf9gwxd/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_092546-mlhd1e60</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/mlhd1e60' target=\"_blank\">vocal-glitter-45</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/mlhd1e60' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/mlhd1e60</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='18' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 18/360 01:00 < 21:28, 0.27 it/s, Epoch 1/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.368986</td>\n      <td>0.569930</td>\n      <td>0.343833</td>\n      <td>0.336014</td>\n      <td>0.278236</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"[I 2025-01-31 09:26:56,517] Trial 27 pruned. \nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.56993</td></tr><tr><td>eval/f1</td><td>0.27824</td></tr><tr><td>eval/loss</td><td>1.36899</td></tr><tr><td>eval/precision</td><td>0.33601</td></tr><tr><td>eval/recall</td><td>0.34383</td></tr><tr><td>eval/runtime</td><td>4.9328</td></tr><tr><td>eval/samples_per_second</td><td>115.959</td></tr><tr><td>eval/steps_per_second</td><td>1.825</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>18</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">vocal-glitter-45</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/mlhd1e60' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/mlhd1e60</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_092546-mlhd1e60/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_092658-xvvl3txs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/xvvl3txs' target=\"_blank\">olive-cherry-46</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/xvvl3txs' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/xvvl3txs</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='72' max='1420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  72/1420 01:06 < 21:28, 1.05 it/s, Epoch 1/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.302650</td>\n      <td>0.725524</td>\n      <td>0.344872</td>\n      <td>0.351976</td>\n      <td>0.300305</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n[I 2025-01-31 09:28:12,585] Trial 28 pruned. \nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at Sakonii/distilbert-base-nepali and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.72552</td></tr><tr><td>eval/f1</td><td>0.3003</td></tr><tr><td>eval/loss</td><td>1.30265</td></tr><tr><td>eval/precision</td><td>0.35198</td></tr><tr><td>eval/recall</td><td>0.34487</td></tr><tr><td>eval/runtime</td><td>5.0694</td></tr><tr><td>eval/samples_per_second</td><td>112.834</td></tr><tr><td>eval/steps_per_second</td><td>7.101</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>72</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">olive-cherry-46</strong> at: <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/xvvl3txs' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/xvvl3txs</a><br> View project at: <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250131_092658-xvvl3txs/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250131_092814-2fl2iu2v</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/2fl2iu2v' target=\"_blank\">glamorous-lion-47</a></strong> to <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tamangangel2057-student/huggingface' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tamangangel2057-student/huggingface/runs/2fl2iu2v' target=\"_blank\">https://wandb.ai/tamangangel2057-student/huggingface/runs/2fl2iu2v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1430' max='5720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1430/5720 06:23 < 19:12, 3.72 it/s, Epoch 5/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.340544</td>\n      <td>0.694056</td>\n      <td>0.339080</td>\n      <td>0.426248</td>\n      <td>0.294101</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.222200</td>\n      <td>0.911521</td>\n      <td>0.708042</td>\n      <td>0.611923</td>\n      <td>0.501506</td>\n      <td>0.529772</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.222200</td>\n      <td>1.348968</td>\n      <td>0.674825</td>\n      <td>0.487626</td>\n      <td>0.378393</td>\n      <td>0.398511</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.002600</td>\n      <td>1.704938</td>\n      <td>0.713287</td>\n      <td>0.407310</td>\n      <td>0.472856</td>\n      <td>0.408678</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.002600</td>\n      <td>1.266793</td>\n      <td>0.722028</td>\n      <td>0.538821</td>\n      <td>0.453645</td>\n      <td>0.481471</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n[I 2025-01-31 09:34:44,646] Trial 29 pruned. \n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"best_trials","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T09:34:44.652516Z","iopub.execute_input":"2025-01-31T09:34:44.652893Z","iopub.status.idle":"2025-01-31T09:34:44.658309Z","shell.execute_reply.started":"2025-01-31T09:34:44.652857Z","shell.execute_reply":"2025-01-31T09:34:44.657482Z"}},"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"BestRun(run_id='20', objective=0.5465236447783807, hyperparameters={'optimizer': 'adamw_bnb_8bit', 'learning_rate': 3.069428769798208e-05, 'per_device_train_batch_size': 16, 'eval_batch_size': 32, 'weight_decay': 0.03234878918376074, 'warmup_ratio': 0.12690580927347275, 'grad_acc_steps': 4}, run_summary=None)"},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"checkpoint_path = \"/kaggle/working/BERT_Classifier_v2/run-2/checkpoint-1144\"\nmodel2 = AutoModelForSequenceClassification.from_pretrained(checkpoint_path)\ntokenizer = AutoTokenizer.from_pretrained(\"Sakonii/distilbert-base-nepali\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T10:23:05.182236Z","iopub.execute_input":"2025-01-31T10:23:05.182568Z","iopub.status.idle":"2025-01-31T10:23:05.541662Z","shell.execute_reply.started":"2025-01-31T10:23:05.182542Z","shell.execute_reply":"2025-01-31T10:23:05.541013Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"training_args2 = TrainingArguments(\n    output_dir=\"./tmp\",\n    per_device_eval_batch_size=32,\n    do_train= False,\n    do_eval= True,\n    metric_for_best_model= \"f1\",\n    load_best_model_at_end= True,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n)\n\n# Recreate the Trainer\ntrainer2 = Trainer(\n    model=model2,\n    args=training_args2,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,  \n    eval_dataset=validation_tokenized,       \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T10:23:08.583971Z","iopub.execute_input":"2025-01-31T10:23:08.584366Z","iopub.status.idle":"2025-01-31T10:23:10.060106Z","shell.execute_reply.started":"2025-01-31T10:23:08.584333Z","shell.execute_reply":"2025-01-31T10:23:10.059432Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-65-60308b68da68>:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer2 = Trainer(\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"# Evaluate on the validation set\nresults = trainer2.evaluate()\nprint(\"Evaluation Results:\", results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T10:23:11.844599Z","iopub.execute_input":"2025-01-31T10:23:11.844903Z","iopub.status.idle":"2025-01-31T10:23:16.383617Z","shell.execute_reply.started":"2025-01-31T10:23:11.844880Z","shell.execute_reply":"2025-01-31T10:23:16.382698Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Evaluation Results: {'eval_loss': 0.7021008729934692, 'eval_accuracy': 0.756993006993007, 'eval_recall': 0.6998715782856806, 'eval_precision': 0.5779416846195343, 'eval_f1': 0.6152815934065934, 'eval_runtime': 4.5161, 'eval_samples_per_second': 126.657, 'eval_steps_per_second': 1.993}\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"# Printing hyperparameters\nimport torch\n\ntraining_args_log = torch.load(f\"{checkpoint_path}/training_args.bin\")\n\n# Print all hyperparameters\nprint(\"Hyperparameters:\")\nfor key, value in training_args_log.to_dict().items():\n    print(f\"{key}: {value}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T10:26:09.932848Z","iopub.execute_input":"2025-01-31T10:26:09.933175Z","iopub.status.idle":"2025-01-31T10:26:10.013959Z","shell.execute_reply.started":"2025-01-31T10:26:09.933149Z","shell.execute_reply":"2025-01-31T10:26:10.013070Z"}},"outputs":[{"name":"stdout","text":"Hyperparameters:\noutput_dir: /kaggle/working/BERT_Classifier_v2\noverwrite_output_dir: True\ndo_train: False\ndo_eval: True\ndo_predict: False\neval_strategy: epoch\nprediction_loss_only: False\nper_device_train_batch_size: 4\nper_device_eval_batch_size: 32\nper_gpu_train_batch_size: None\nper_gpu_eval_batch_size: None\ngradient_accumulation_steps: 1\neval_accumulation_steps: None\neval_delay: 0\ntorch_empty_cache_steps: None\nlearning_rate: 1.9165942005355648e-05\nweight_decay: 0.09172868307357833\nadam_beta1: 0.9\nadam_beta2: 0.999\nadam_epsilon: 1e-08\nmax_grad_norm: 1.0\nnum_train_epochs: 20\nmax_steps: -1\nlr_scheduler_type: linear\nlr_scheduler_kwargs: {}\nwarmup_ratio: 0.17707559519779958\nwarmup_steps: 0\nlog_level: passive\nlog_level_replica: warning\nlog_on_each_node: True\nlogging_dir: /kaggle/working/BERT_Classifier_v2/runs/Jan31_06-55-42_f92e2c842e43\nlogging_strategy: steps\nlogging_first_step: False\nlogging_steps: 500\nlogging_nan_inf_filter: True\nsave_strategy: epoch\nsave_steps: 500\nsave_total_limit: 1\nsave_safetensors: True\nsave_on_each_node: True\nsave_only_model: False\nrestore_callback_states_from_checkpoint: False\nno_cuda: False\nuse_cpu: False\nuse_mps_device: False\nseed: 42\ndata_seed: None\njit_mode_eval: False\nuse_ipex: False\nbf16: True\nfp16: False\nfp16_opt_level: O1\nhalf_precision_backend: auto\nbf16_full_eval: False\nfp16_full_eval: False\ntf32: None\nlocal_rank: 0\nddp_backend: None\ntpu_num_cores: None\ntpu_metrics_debug: False\ndebug: []\ndataloader_drop_last: False\neval_steps: None\ndataloader_num_workers: 0\ndataloader_prefetch_factor: None\npast_index: -1\nrun_name: None\ndisable_tqdm: False\nremove_unused_columns: True\nlabel_names: None\nload_best_model_at_end: True\nmetric_for_best_model: f1\ngreater_is_better: True\nignore_data_skip: False\nfsdp: []\nfsdp_min_num_params: 0\nfsdp_config: {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}\nfsdp_transformer_layer_cls_to_wrap: None\naccelerator_config: {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}\ndeepspeed: None\nlabel_smoothing_factor: 0.0\noptim: adamw_bnb_8bit\noptim_args: None\nadafactor: False\ngroup_by_length: False\nlength_column_name: length\nreport_to: ['wandb']\nddp_find_unused_parameters: None\nddp_bucket_cap_mb: None\nddp_broadcast_buffers: None\ndataloader_pin_memory: True\ndataloader_persistent_workers: False\nskip_memory_metrics: True\nuse_legacy_prediction_loop: False\npush_to_hub: False\nresume_from_checkpoint: None\nhub_model_id: None\nhub_strategy: every_save\nhub_token: <HUB_TOKEN>\nhub_private_repo: None\nhub_always_push: False\ngradient_checkpointing: False\ngradient_checkpointing_kwargs: None\ninclude_inputs_for_metrics: False\ninclude_for_metrics: []\neval_do_concat_batches: True\nfp16_backend: auto\nevaluation_strategy: None\npush_to_hub_model_id: None\npush_to_hub_organization: None\npush_to_hub_token: <PUSH_TO_HUB_TOKEN>\nmp_parameters: \nauto_find_batch_size: False\nfull_determinism: False\ntorchdynamo: None\nray_scope: last\nddp_timeout: 1800\ntorch_compile: False\ntorch_compile_backend: None\ntorch_compile_mode: None\ndispatch_batches: None\nsplit_batches: None\ninclude_tokens_per_second: False\ninclude_num_input_tokens_seen: False\nneftune_noise_alpha: None\noptim_target_modules: None\nbatch_eval_metrics: False\neval_on_start: False\nuse_liger_kernel: False\neval_use_gather_object: False\naverage_tokens_across_devices: False\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-67-a998aea24be9>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  training_args_log = torch.load(f\"{checkpoint_path}/training_args.bin\")\n","output_type":"stream"}],"execution_count":67},{"cell_type":"code","source":"wandb.init()\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n\n# # Load the test dataset\n# test_dataset = load_from_disk(\"/kaggle/working/validation_tokenized\")\n\npredictions = trainer2.predict(validation_tokenized)\nfinal_predictions = np.argmax(predictions.predictions, axis=1)\n\nlabel_map = {\n    0: 'GENERAL',\n    1: 'PROFANITY_0',\n    2: 'PROFANITY_1',\n    3: 'VIOLENCE'\n}\n\nprediction_data = []\nfor gt, pt in zip(validation_tokenized['labels'], final_predictions):\n    prediction_data.append([gt, pt])\n    \nprediction_df = pd.DataFrame(prediction_data, columns=['labels', 'predictions'])\n# Convert tensor labels to integers\nprediction_df['labels'] = prediction_df['labels'].apply(lambda x: x.item() if isinstance(x, torch.Tensor) else x)\n\nreport = classification_report(y_true=prediction_df['labels'], y_pred=prediction_df['predictions'])\nprint(report)\n\n# Confusion matrix\ncm = confusion_matrix(y_true= prediction_df['labels'], y_pred= prediction_df['predictions'])\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(prediction_df['labels']))\ndisp.plot(cmap='Blues', values_format='d')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T10:29:17.585903Z","iopub.execute_input":"2025-01-31T10:29:17.586198Z","iopub.status.idle":"2025-01-31T10:29:22.713718Z","shell.execute_reply.started":"2025-01-31T10:29:17.586175Z","shell.execute_reply":"2025-01-31T10:29:22.712824Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.94      0.79      0.86       452\n           1       0.32      0.70      0.44        50\n           2       0.57      0.76      0.65        17\n           3       0.49      0.55      0.52        53\n\n    accuracy                           0.76       572\n   macro avg       0.58      0.70      0.62       572\nweighted avg       0.83      0.76      0.78       572\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAfsAAAHHCAYAAAC4M/EEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABULElEQVR4nO3deVwU9f8H8NeCsoCwICqXAoooSoq3Rt63eKdlHimaRwdoeWdfD9QUU/NMsUNFTcpb07w1MRNNKRQvEkRB5VAJFlDOnd8f/thawWRZ2GVnXs8e83g4n/nMzHv2sfHezzEzMkEQBBAREZFomRg6ACIiIipfTPZEREQix2RPREQkckz2REREIsdkT0REJHJM9kRERCLHZE9ERCRyTPZEREQix2RPREQkckz2RC+4ffs2evToARsbG8hkMuzfv79Mj3/37l3IZDKEhISU6XGNWadOndCpUydDh0EkWkz2VCHFxsbi/fffh7u7O8zNzaFQKNC2bVusXr0az549K9dz+/n5ISoqCosWLcK2bdvQsmXLcj2fPo0ePRoymQwKhaLYz/H27duQyWSQyWRYvny51sd/+PAhAgMDERkZWQbRElFZqWToAIhe9PPPP+Ptt9+GXC7HqFGj0KhRI+Tm5uLcuXOYPn06rl+/jm+++aZczv3s2TOEh4fjf//7HwICAsrlHG5ubnj27BkqV65cLsd/lUqVKuHp06c4ePAghgwZorFt+/btMDc3R3Z2dqmO/fDhQ8yfPx+1a9dG06ZNS7zf8ePHS3U+IioZJnuqUOLi4jB06FC4ubnh9OnTcHJyUm/z9/dHTEwMfv7553I7/6NHjwAAtra25XYOmUwGc3Pzcjv+q8jlcrRt2xY//PBDkWQfGhqKPn36YM+ePXqJ5enTp7C0tISZmZlezkckVezGpwpl6dKlyMzMxMaNGzUSfSEPDw98/PHH6vX8/HwsXLgQdevWhVwuR+3atfHZZ58hJydHY7/atWujb9++OHfuHFq3bg1zc3O4u7tj69at6jqBgYFwc3MDAEyfPh0ymQy1a9cG8Lz7u/Df/xYYGAiZTKZRduLECbRr1w62trawsrKCp6cnPvvsM/X2l43Znz59Gu3bt0eVKlVga2uLAQMG4ObNm8WeLyYmBqNHj4atrS1sbGwwZswYPH369OUf7AuGDx+OI0eOIC0tTV126dIl3L59G8OHDy9SPzU1FdOmTUPjxo1hZWUFhUIBX19fXLlyRV3nzJkzaNWqFQBgzJgx6uGAwuvs1KkTGjVqhIiICHTo0AGWlpbqz+XFMXs/Pz+Ym5sXuf6ePXuiatWqePjwYYmvlYiY7KmCOXjwINzd3fHGG2+UqP64ceMwd+5cNG/eHCtXrkTHjh0RFBSEoUOHFqkbExODt956C927d8eXX36JqlWrYvTo0bh+/ToAYNCgQVi5ciUAYNiwYdi2bRtWrVqlVfzXr19H3759kZOTgwULFuDLL79E//798dtvv/3nfidPnkTPnj2RkpKCwMBATJkyBefPn0fbtm1x9+7dIvWHDBmCjIwMBAUFYciQIQgJCcH8+fNLHOegQYMgk8mwd+9edVloaCgaNGiA5s2bF6l/584d7N+/H3379sWKFSswffp0REVFoWPHjurE27BhQyxYsAAAMGHCBGzbtg3btm1Dhw4d1Md58uQJfH190bRpU6xatQqdO3cuNr7Vq1ejRo0a8PPzQ0FBAQDg66+/xvHjx7F27Vo4OzuX+FqJCIBAVEGkp6cLAIQBAwaUqH5kZKQAQBg3bpxG+bRp0wQAwunTp9Vlbm5uAgDh7Nmz6rKUlBRBLpcLU6dOVZfFxcUJAIRly5ZpHNPPz09wc3MrEsO8efOEf/9vtHLlSgGA8OjRo5fGXXiOzZs3q8uaNm0q2NvbC0+ePFGXXblyRTAxMRFGjRpV5HzvvfeexjHffPNNoVq1ai8957+vo0qVKoIgCMJbb70ldO3aVRAEQSgoKBAcHR2F+fPnF/sZZGdnCwUFBUWuQy6XCwsWLFCXXbp0qci1FerYsaMAQNiwYUOx2zp27KhRduzYMQGA8Pnnnwt37twRrKyshIEDB77yGomoKLbsqcJQKpUAAGtr6xLVP3z4MABgypQpGuVTp04FgCJj+15eXmjfvr16vUaNGvD09MSdO3dKHfOLCsf6Dxw4AJVKVaJ9EhMTERkZidGjR8POzk5d7u3tje7du6uv898++OADjfX27dvjyZMn6s+wJIYPH44zZ84gKSkJp0+fRlJSUrFd+MDzcX4Tk+d/LgoKCvDkyRP1EMUff/xR4nPK5XKMGTOmRHV79OiB999/HwsWLMCgQYNgbm6Or7/+usTnIqJ/MNlThaFQKAAAGRkZJap/7949mJiYwMPDQ6Pc0dERtra2uHfvnka5q6trkWNUrVoVf//9dykjLuqdd95B27ZtMW7cODg4OGDo0KHYuXPnfyb+wjg9PT2LbGvYsCEeP36MrKwsjfIXr6Vq1aoAoNW19O7dG9bW1tixYwe2b9+OVq1aFfksC6lUKqxcuRL16tWDXC5H9erVUaNGDVy9ehXp6eklPmfNmjW1moy3fPly2NnZITIyEmvWrIG9vX2J9yWifzDZU4WhUCjg7OyMa9euabXfixPkXsbU1LTYckEQSn2OwvHkQhYWFjh79ixOnjyJkSNH4urVq3jnnXfQvXv3InV1ocu1FJLL5Rg0aBC2bNmCffv2vbRVDwCLFy/GlClT0KFDB3z//fc4duwYTpw4gddee63EPRjA889HG3/++SdSUlIAAFFRUVrtS0T/YLKnCqVv376IjY1FeHj4K+u6ublBpVLh9u3bGuXJyclIS0tTz6wvC1WrVtWYuV7oxd4DADAxMUHXrl2xYsUK3LhxA4sWLcLp06fxyy+/FHvswjijo6OLbLt16xaqV6+OKlWq6HYBLzF8+HD8+eefyMjIKHZSY6Hdu3ejc+fO2LhxI4YOHYoePXqgW7duRT6Tkv7wKomsrCyMGTMGXl5emDBhApYuXYpLly6V2fGJpITJniqUGTNmoEqVKhg3bhySk5OLbI+NjcXq1asBPO+GBlBkxvyKFSsAAH369CmzuOrWrYv09HRcvXpVXZaYmIh9+/Zp1EtNTS2yb+HDZV68HbCQk5MTmjZtii1btmgkz2vXruH48ePq6ywPnTt3xsKFC/HVV1/B0dHxpfVMTU2L9Brs2rULDx480Cgr/FFS3A8jbc2cORPx8fHYsmULVqxYgdq1a8PPz++lnyMRvRwfqkMVSt26dREaGop33nkHDRs21HiC3vnz57Fr1y6MHj0aANCkSRP4+fnhm2++QVpaGjp27Ijff/8dW7ZswcCBA196W1dpDB06FDNnzsSbb76JSZMm4enTpwgODkb9+vU1JqgtWLAAZ8+eRZ8+feDm5oaUlBSsX78etWrVQrt27V56/GXLlsHX1xc+Pj4YO3Ysnj17hrVr18LGxgaBgYFldh0vMjExwezZs19Zr2/fvliwYAHGjBmDN954A1FRUdi+fTvc3d016tWtWxe2trbYsGEDrK2tUaVKFbRp0wZ16tTRKq7Tp09j/fr1mDdvnvpWwM2bN6NTp06YM2cOli5dqtXxiCTPwHcDEBXrr7/+EsaPHy/Url1bMDMzE6ytrYW2bdsKa9euFbKzs9X18vLyhPnz5wt16tQRKleuLLi4uAizZs3SqCMIz2+969OnT5HzvHjL18tuvRMEQTh+/LjQqFEjwczMTPD09BS+//77IrfenTp1ShgwYIDg7OwsmJmZCc7OzsKwYcOEv/76q8g5Xrw97eTJk0Lbtm0FCwsLQaFQCP369RNu3LihUafwfC/e2rd582YBgBAXF/fSz1QQNG+9e5mX3Xo3depUwcnJSbCwsBDatm0rhIeHF3vL3IEDBwQvLy+hUqVKGtfZsWNH4bXXXiv2nP8+jlKpFNzc3ITmzZsLeXl5GvUmT54smJiYCOHh4f95DUSkSSYIWszoISIiIqPDMXsiIiKRY7InIiISOSZ7IiIikWOyJyIiEjkmeyIiIpFjsiciIhI5o36ojkqlwsOHD2FtbV2mj+kkIiL9EAQBGRkZcHZ2Vr9ZsTxkZ2cjNzdX5+OYmZnB3Ny8DCLSL6NO9g8fPoSLi4uhwyAiIh0lJCSgVq1a5XLs7OxsWFhXA/Kf6nwsR0dHxMXFGV3CN+pkX/jeczMvP8hMS/7aTCq9MzsCDR2C5LhWtzR0CJLyLLfs3k5Ir5aRkYFmDeuo/56Xh9zcXCD/KeRefoAuuaIgF0k3tiA3N5fJXp8Ku+5lpmZM9npiZa0wdAiSo1Aw2etTJSZ7g9DLUGwlc51yhSDTbpghODgYwcHBuHv3LgDgtddew9y5c+Hr6wsA6NSpE8LCwjT2ef/997Fhwwb1enx8PD788EP88ssvsLKygp+fH4KCglCpknbp26iTPRERUYnJAOjyo0LLXWvVqoUlS5agXr16EAQBW7ZswYABA/Dnn3/itddeAwCMHz8eCxYsUO9jafnPj/uCggL06dMHjo6OOH/+PBITEzFq1ChUrlwZixcv1ioWJnsiIpIGmcnzRZf9tdCvXz+N9UWLFiE4OBgXLlxQJ3tLS8uXvl76+PHjuHHjBk6ePAkHBwc0bdoUCxcuxMyZMxEYGAgzs5L3UvDWOyIiIi0olUqNJScn55X7FBQU4Mcff0RWVhZ8fHzU5du3b0f16tXRqFEjzJo1C0+f/jOJMDw8HI0bN4aDg4O6rGfPnlAqlbh+/bpWMbNlT0RE0iCT6diN/3zfF+8CmzdvHgIDA4vdJSoqCj4+PsjOzoaVlRX27dsHLy8vAMDw4cPh5uYGZ2dnXL16FTNnzkR0dDT27t0LAEhKStJI9ADU60lJSVqFzmRPRETSUEbd+AkJCVAo/pmsLJfLX7qLp6cnIiMjkZ6ejt27d8PPzw9hYWHw8vLChAkT1PUaN24MJycndO3aFbGxsahbt27p4ywGu/GJiIi0oFAoNJb/SvZmZmbw8PBAixYtEBQUhCZNmmD16tXF1m3Tpg0AICYmBsDze/qTk5M16hSuv2yc/2WY7ImISBoKu/F1WXSkUqleOsYfGRkJAHBycgIA+Pj4ICoqCikpKeo6J06cgEKhUA8FlBS78YmISCJ07MbXsn08a9Ys+Pr6wtXVFRkZGQgNDcWZM2dw7NgxxMbGIjQ0FL1790a1atVw9epVTJ48GR06dIC3tzcAoEePHvDy8sLIkSOxdOlSJCUlYfbs2fD39//P3oTiMNkTERGVg5SUFIwaNQqJiYmwsbGBt7c3jh07hu7duyMhIQEnT57EqlWrkJWVBRcXFwwePBizZ89W729qaopDhw7hww8/hI+PD6pUqQI/Pz+N+/JLismeiIikoYxm45fUxo0bX7rNxcWlyNPziuPm5obDhw9rdd7iMNkTEZE06PmhOhWJ8UZOREREJcKWPRERSYOeu/ErEiZ7IiKSBgl34zPZExGRNEi4ZW+8P1OIiIioRNiyJyIiaWA3PhERkcjJZDome3bjExERUQXFlj0REUmDiez5osv+RorJnoiIpEHCY/bGGzkRERGVCFv2REQkDRK+z57JnoiIpIHd+ERERCRWbNkTEZE0sBufiIhI5CTcjc9kT0RE0iDhlr3x/kwhIiKiEmHLnoiIpIHd+ERERCLHbnwiIiISK7bsiYhIInTsxjfi9jGTPRERSQO78YmIiEis2LInIiJpkMl0nI1vvC17JnsiIpIGCd96Z7yRExERUYmwZV9G3hvcDu8Nbg8XJzsAwK07SVi28QhOnr8BADi44WO0a1FPY5/Ne85hypIfNcqG9W0D/+FdUNfVHhlZ2Thw6k9MX7pTPxchAilP0rE25AjCI/5Cdk4uajlVw9yP34ZXvVpF6gat24e9Ry9i8ri+GD6gnQGiFZ/mAwORkJRapHzM4HZYOn2IASISl3Xfn8TRs1cRey8F5vLKaNGoNj79oB/qutqr67wz6StciIzV2G9Efx8snsbPX8oT9CpEsl+3bh2WLVuGpKQkNGnSBGvXrkXr1q0NHZZWHqakYf5XBxCb8AgymQzD+rTB9uUT0PHdJbh1JwkAELLvNwR9fUi9z7PsPI1jfDS8C/xHdMG8Nftx+dpdVLEwg6tzNb1ehzFTZj7FuBnBaNG4LlYHjoGtogoSHj6GwsqiSN1fwq8hKjoeNewUBohUvI5vnooClaBevxWbiLcmrcOALs0MGJV4XIyMxag326FJAxfkF6iw9JufMXLqBpzcOhOWFnJ1vWH9XseU93zV6xbmZoYIt+KRcDe+wZP9jh07MGXKFGzYsAFt2rTBqlWr0LNnT0RHR8Pe3v7VB6ggjv56TWP98+CDeG9wO7RsVEed7J9l5yLlSUax+9tYW+B/H/bFsCkbcPbSX+ry6zEPyy9okdmyOwwO1W0x75O31WU1He2K1Et5ko7lX/+ENfPHYvKCzfoMUfSqV7XWWF+z9QRq16qON5p7GCgicdm6/H2N9S8/G47m/ecgKvo+2jStqy63kJvBvhp/yBYh4Za9wX+mrFixAuPHj8eYMWPg5eWFDRs2wNLSEps2bTJ0aKVmYiLDoO4tYGlhhktRceryt3u1RMyJJTj/42eY698fFvLK6m2d2zSAiUwGpxq2uLBzNq4dWohNi99DTQdbA1yBcfr195to6FETny7Zjh7vLsSIj1dj37HfNeqoVCrMW7ED7w7qgLpuDgaKVBpy8/Kx++hlDO/7OmRG/EeyIsvIfAYAsFVYapTvPxGBpv1mo7vfF/ji60N4lp1riPCoAjFoyz43NxcRERGYNWuWuszExATdunVDeHh4kfo5OTnIyclRryuVSr3EWVJedZ1xbNNUmJtVQtazHIyc/i2i45636ncfu4yExFQkPUrHa/WcMS9gADzc7DFqxncAgNo1q8PERIYpY3pg1pd7oMx8hv992Bd7vwpAu2FByMsvMOSlGYUHSanYc+Qihg9shzFvd8L12/fx5Tc/oXIlU/Tt2gIAsGVPGExNTDG0X1sDRyt+h8OuIj3zGYb1aWPoUERJpVJh/tr9aNm4DjzdndTlA7o1R01HOzhUU+BmbCKWfH0QsfEp+GbRewaMtoJgN75hPH78GAUFBXBw0GxhOTg44NatW0XqBwUFYf78+foKT2u37yWjw4ggKKwsMKBrM6wPHIm+769GdFwStuz7TV3vRuxDJD1W4qfgSahdszruPngME5kMZpUr4dPlu/HLxefXPu5/IYg+uhjtW9bH6Qs3DXVZRkMlCGjoURP+o3oBADzr1sSde8nYe+Qi+nZtgZsx9/HjT7/h+1WT2NLUg+0HL6Dr6w3hWMPG0KGI0pyVe/BXXCJ2fzVJo3x4/zfU/25Q1xn21RQYPnk97j14DLea1fUdZsXCbnzjMGvWLKSnp6uXhIQEQ4ekIS+/AHH3H+PKrQQsWPcTrt1+gA+Gdiq2bsS1uwAAd5caAICkJ897KQp7AgDgSVomnqRlopZj1XKNWyyqV7WGu4vmPI/aLvZIepQGAPjz+l38nZ6Ffu8twesDPsPrAz5DYkoaVm/6Gf3HLjFAxOKVkJiKs5ei8e4AH0OHIkpzVu7BqfM38MMqfzjZ2/5n3WZergCAuw8e6yEyqqgM2rKvXr06TE1NkZycrFGenJwMR0fHIvXlcjnkcnmR8orKRCaDmVnxH3Hj+s9vBUt+nA4AuHjlDgDAw80eD1PSADwfh6tma4WExKK3MlFRTRq64d4Lf9DiHzyC4///MezduRlaN9WcKDZp7ib4dm6Gft1a6itMSfjh0AVUr2qN7m+8ZuhQREUQBMxdtRfHfo3CjtX+Jbpb53rMAwDghD0AMplMt149tuxLx8zMDC1atMCpU6fUZSqVCqdOnYKPj3G1COb698cbzerCxckOXnWdMde/P9q1qIddRy6jds3qmDa2F5o0cIGLkx18OzRG8PyR+O2P2+rZ9rHxKfj5zBUsmfoWWnvXQcO6TggOHIm/7iXj18t/veLsBADDBrRDVHQ8Nu/8BQkPH+PomUjsO/Y73u7z/Ltkq6gCDzdHjaVSJRNUq2qN2rVqGDh68VCpVPjh54t4p3drVKpkauhwRGX2yj3Yf+Iy1sx9F1Us5Uh5okTKEyWyc55PwLv34DFWbzmOqOgEJCSm4sS5a5iyKBRtmtRFw7rOBo7e8AqTvS6LsTL4rXdTpkyBn58fWrZsidatW2PVqlXIysrCmDFjDB2aVqpXtUJw4Cg4VFdAmZmN6zEPMHjiepz5/RZqOtiiU2tPfDi0MywtzPAg+W8cPB2J5ZuOaRzjw8BtWDR5EHas/BAqlYDf/ryNtyetQ36BykBXZVxeq++CZZ+NxLqtR/Hdj6fg7FAVU8b3g28n3uOtT2GXonE/6W+M6Pe6oUMRne/3P5/7886kdRrly2cNw9u+rVG5kil+u/wXNu0Kw7PsXDjVsIVvR29MHNXDEOFSBSITBEF4dbXy9dVXX6kfqtO0aVOsWbMGbdq8egavUqmEjY0N5I3HQ2bKh0bow6WDHNvWt9o1LF9dicrM01ze+aJPGUolPGpVR3p6OhSK8hlqKMwVFgPWQVa56EO2SkrIe4ZnB/zLNdbyYvCWPQAEBAQgICDA0GEQEZGIccyeiIiIRIvJnoiIJEHfE/SCg4Ph7e0NhUIBhUIBHx8fHDlyRL09Ozsb/v7+qFatGqysrDB48OAid6fFx8ejT58+sLS0hL29PaZPn478/Hytr53JnoiIJEHfyb5WrVpYsmQJIiIicPnyZXTp0gUDBgzA9evXAQCTJ0/GwYMHsWvXLoSFheHhw4cYNGiQev+CggL06dMHubm5OH/+PLZs2YKQkBDMnTtX+2uvCBP0SosT9PSPE/T0jxP09IsT9PRLnxP0rAd/rfMEvYw97+sUq52dHZYtW4a33noLNWrUQGhoKN566y0AwK1bt9CwYUOEh4fj9ddfx5EjR9C3b188fPhQ/aTZDRs2YObMmXj06BHMzEqe99iyJyIi0oJSqdRY/v3OlpcpKCjAjz/+iKysLPj4+CAiIgJ5eXno1q2buk6DBg3g6uqqfjdMeHg4GjdurPFI+Z49e0KpVKp7B0qKyZ6IiKRBVgYLABcXF9jY2KiXoKCgl54yKioKVlZWkMvl+OCDD7Bv3z54eXkhKSkJZmZmsLW11ajv4OCApKTnj01PSkoq9t0xhdu0USFuvSMiIipvZXXrXUJCgkY3/n89xt3T0xORkZFIT0/H7t274efnh7CwsNLHUEpM9kRERFoonF1fEmZmZvDweP5OjhYtWuDSpUtYvXo13nnnHeTm5iItLU2jdf/vd8M4Ojri999/1zhe4Wz94t4f81/YjU9ERJLw/A23uszG1z0GlUqFnJwctGjRApUrV9Z4N0x0dDTi4+PV74bx8fFBVFQUUlJS1HVOnDgBhUIBLy8vrc7Llj0REUmCDLq+zEa7fWfNmgVfX1+4uroiIyMDoaGhOHPmDI4dOwYbGxuMHTsWU6ZMgZ2dHRQKBSZOnAgfHx+8/vrz90r06NEDXl5eGDlyJJYuXYqkpCTMnj0b/v7+Wr8BlsmeiIioHKSkpGDUqFFITEyEjY0NvL29cezYMXTv3h0AsHLlSpiYmGDw4MHIyclBz549sX79evX+pqamOHToED788EP4+PigSpUq8PPzw4IFC7SOhcmeiIgkQd/Pxt+4ceN/bjc3N8e6deuwbt26l9Zxc3PD4cOHtTpvcZjsiYhIGv51+1yp9zdSnKBHREQkcmzZExGRNOjYjS8Y8StumeyJiEgSdB2z120mv2Ex2RMRkSRIOdlzzJ6IiEjk2LInIiJpkPBsfCZ7IiKSBHbjExERkWixZU9ERJIg5ZY9kz0REUmClJM9u/GJiIhEji17IiKSBCm37JnsiYhIGiR86x278YmIiESOLXsiIpIEduMTERGJHJM9ERGRyEk52XPMnoiISOTYsiciImmQ8Gx8JnsiIpIEduMTERGRaLFlT0REkiDllj2TPRERSYIMOiZ7Ix60Zzc+ERGRyLFlT0REksBufCIiIrHjrXfGLebkUigUCkOHIQnKZ3mGDkFyKplytE2frORG/BfdCKnkokhDFR4/ZSIikgR24xMREYkckz0REZHIyWTPF132N1YcDCQiIhI5tuyJiEgSnrfsdenGL8Ng9IzJnoiIpEHHbnxjvvWO3fhEREQix5Y9ERFJAmfjExERiRxn4xMREZFosWVPRESSYGIig4lJ6Zvngg77GhqTPRERSQK78YmIiEi0mOyJiEgSCmfj67JoIygoCK1atYK1tTXs7e0xcOBAREdHa9Tp1KlTkXN88MEHGnXi4+PRp08fWFpawt7eHtOnT0d+fr5WsbAbn4iIJEHf3fhhYWHw9/dHq1atkJ+fj88++ww9evTAjRs3UKVKFXW98ePHY8GCBep1S0tL9b8LCgrQp08fODo64vz580hMTMSoUaNQuXJlLF68uMSxMNkTEZEk6Ps++6NHj2qsh4SEwN7eHhEREejQoYO63NLSEo6OjsUe4/jx47hx4wZOnjwJBwcHNG3aFAsXLsTMmTMRGBgIMzOzEsXCbnwiIiItKJVKjSUnJ6dE+6WnpwMA7OzsNMq3b9+O6tWro1GjRpg1axaePn2q3hYeHo7GjRvDwcFBXdazZ08olUpcv369xDGzZU9ERJJQVi17FxcXjfJ58+YhMDDwP/dVqVT45JNP0LZtWzRq1EhdPnz4cLi5ucHZ2RlXr17FzJkzER0djb179wIAkpKSNBI9APV6UlJSiWNnsiciIkkoqzH7hIQEKBQKdblcLn/lvv7+/rh27RrOnTunUT5hwgT1vxs3bgwnJyd07doVsbGxqFu3bumDfQG78YmIiLSgUCg0llcl+4CAABw6dAi//PILatWq9Z9127RpAwCIiYkBADg6OiI5OVmjTuH6y8b5i8NkT0REkiCDjrfeafmOW0EQEBAQgH379uH06dOoU6fOK/eJjIwEADg5OQEAfHx8EBUVhZSUFHWdEydOQKFQwMvLq8SxsBufiIgkQd+33vn7+yM0NBQHDhyAtbW1eozdxsYGFhYWiI2NRWhoKHr37o1q1arh6tWrmDx5Mjp06ABvb28AQI8ePeDl5YWRI0di6dKlSEpKwuzZs+Hv71+i4YNCbNkTERGVg+DgYKSnp6NTp05wcnJSLzt27AAAmJmZ4eTJk+jRowcaNGiAqVOnYvDgwTh48KD6GKampjh06BBMTU3h4+ODd999F6NGjdK4L78k2LInIiJJ0Pd99oIg/Od2FxcXhIWFvfI4bm5uOHz4sFbnfhGTPRERSQJfhENERESixZY9ERFJgr678SsSJnsiIpIEKXfjM9kTEZEkSLllzzF7IiIikWPLnoiIpEHHbnwtH6BXoTDZExGRJLAbn4iIiESLLXsiIpIEzsYnIiISOXbjExERkWixZU9ERJLAbnwiIiKRYzc+ERERiRZb9kREJAlSbtkz2Zej8D9jsG77KVyNTkDyYyU2LxmH3h291dt/PnMFW/adw9VbCfhb+RSntsxAo/q1DBixcdt+4Dx+OHge95NSAQD1ajsiYGR3dGzTEAAwYvJ6/H4lVmOfof18sHDyW3qPVax++yMGa7edxJVb8Uh6rMT3y8ajT6cmhg5LtDbt+RWb955D/MPn3/kG7o6YPrYXur3xmoEjq5ikPGZv0G78s2fPol+/fnB2doZMJsP+/fsNGU6Ze5qdi9fq1cSSqW8Xv/1ZDtp4u2O2f389RyZOjjVsMG1cH+zfMBn7gifDp5kHPpyzGbfjktR13unzOs7vnqdeZkzoa8CIxefpsxw0ql8Ty2a8Y+hQJMHZ3hZzP+qP01um49SW6Wjfsj7enf4tbt1JNHRoFVJhy16XxVgZtGWflZWFJk2a4L333sOgQYMMGUq56Orjha4+Xi/d/rZvawBAfOITfYUkal1faM1MGdsboT+dR+TNe6hXxxEAYC6vjBp2CkOEJwnd276G7m3ZqtSXXu0ba6zP/rAfNu89h8vX7qKBu5OBoqKKyKDJ3tfXF76+voYMgUSqoECFI2FX8DQ7F0293NTlP536Az+djEB1OwW6+HjBf2R3WJibGTBSorJRUKDCgVN/4umzXLRsVNvQ4VRIUu7G55g9iUr0nUQMCViDnNx8WFqYYf38MahX+3mrvl/XZqjpUBX21Wxw685DLPvmZ9xJeIT1C0YbNmgiHdyIeYhe475Edm4+qljIsfWLcWzVvwQn6BmJnJwc5OTkqNeVSqUBo6GKqI5LDfz07VRkZD3D0bCrmPHFD9i+8iPUq+2IoX191PU83Z1gb6fAqGkbcO/BY7jVrG7AqIlKz8PNHme2fQpl5jP8dDoS/gu+x0/Bk5jwSYNR3WcfFBQEGxsb9eLi4mLokKiCMatcCW41q6NRfRdMG98HDes6Y8veX4ut26ShKwAg/uFjfYZIVKbMKleCu0sNNG3oirn+/fFaPWd8syPM0GFVSDL805VfqsXQF6ADo0r2s2bNQnp6unpJSEgwdEhUwalUAnLz8ovddjP2IQBwwh6JikolICcvz9BhVEgmMpnOi7Eyqm58uVwOuVxu6DBKLOtpDuLuP1Kvxz98gmt/3YetwhK1HO3wd3oWHiT/jaTH6QCAmPgUAIB9NQXsqzEBaWv5tz+jQ+sGcHaoiqynOTh46g9cvBKLTV+Mx70Hj3Hw9J/o1KYBbBVVEB37EIvW/4RW3u5oUNfZ0KGLRubTHMQl/POdv/fwCaKi78PWxhIujnYGjEycFqz7Cd3e8EIth6rIfJqD3ccu47c/YrBr9UeGDo0qGIMm+8zMTMTExKjX4+LiEBkZCTs7O7i6uhowsrIReSseg/zXqtfnrdkHAHind2usmfMujp27ho8/367e/v6cEADAtLG9MH1cb73GKgZP0jIxY8kPSElVwrqKBRq4O2HTF+PRrqUnElP+xvmIv7Blz1k8fZYLJ3tb9OzQGB+9293QYYtK5M176PfBGvX6/1buBQAM69MG6wNHGios0Xr8dwY+mr8NyY+VUFiZw8vDGbtWf4TObRoYOrQKScqz8WWCIAiGOvmZM2fQuXPnIuV+fn4ICQl55f5KpRI2NjZISP4bCgVbwvqgfMbuQX2rbm08vVlioFIZ7E+iJCmVSjjVsEV6enq5/R0vzBVdlp9CJYsqpT5O/rMsnJ7WtVxjLS8Gbdl36tQJBvytQUREEmIie77osr+xMqoJekRERKQ9o5qgR0REVGoyHR+MY8QteyZ7IiKSBClP0GM3PhERkcixZU9ERJIg+///dNnfWDHZExGRJHA2PhEREYkWW/ZERCQJfMXtK/z0008lPmD//v1LHQwREVF5kfJs/BIl+4EDB5boYDKZDAUFBbrEQ0RERGWsRMlepVKVdxxERETlStfX1Er2FbfZ2dkwNzcvq1iIiIjKjZS78bWejV9QUICFCxeiZs2asLKywp07dwAAc+bMwcaNG8s8QCIiorJQOEFPl8VYaZ3sFy1ahJCQECxduhRmZmbq8kaNGuG7774r0+CIiIiMVVBQEFq1agVra2vY29tj4MCBiI6O1qiTnZ0Nf39/VKtWDVZWVhg8eDCSk5M16sTHx6NPnz6wtLSEvb09pk+fjvz8fK1i0TrZb926Fd988w1GjBgBU1NTdXmTJk1w69YtbQ9HRESkF4Xd+Los2ggLC4O/vz8uXLiAEydOIC8vDz169EBWVpa6zuTJk3Hw4EHs2rULYWFhePjwIQYNGqTeXlBQgD59+iA3Nxfnz5/Hli1bEBISgrlz52oVi9Zj9g8ePICHh0eRcpVKhby8PG0PR0REpBf6nqB39OhRjfWQkBDY29sjIiICHTp0QHp6OjZu3IjQ0FB06dIFALB582Y0bNgQFy5cwOuvv47jx4/jxo0bOHnyJBwcHNC0aVMsXLgQM2fORGBgoEYP+3/GrlXkALy8vPDrr78WKd+9ezeaNWum7eGIiIiMilKp1FhycnJKtF96ejoAwM7ODgAQERGBvLw8dOvWTV2nQYMGcHV1RXh4OAAgPDwcjRs3hoODg7pOz549oVQqcf369RLHrHXLfu7cufDz88ODBw+gUqmwd+9eREdHY+vWrTh06JC2hyMiItILGXR7JX3hvi4uLhrl8+bNQ2Bg4H/uq1Kp8Mknn6Bt27Zo1KgRACApKQlmZmawtbXVqOvg4ICkpCR1nX8n+sLthdtKSutkP2DAABw8eBALFixAlSpVMHfuXDRv3hwHDx5E9+7dtT0cERGRXpTV43ITEhKgUCjU5XK5/JX7+vv749q1azh37lypz6+LUt1n3759e5w4caKsYyEiIqrwFAqFRrJ/lYCAABw6dAhnz55FrVq11OWOjo7Izc1FWlqaRus+OTkZjo6O6jq///67xvEKZ+sX1imJUr/17vLly9i2bRu2bduGiIiI0h6GiIhILwpfcavLog1BEBAQEIB9+/bh9OnTqFOnjsb2Fi1aoHLlyjh16pS6LDo6GvHx8fDx8QEA+Pj4ICoqCikpKeo6J06cgEKhgJeXV4lj0bplf//+fQwbNgy//fab+pdIWloa3njjDfz4448av1qIiIgqCn2/9c7f3x+hoaE4cOAArK2t1WPsNjY2sLCwgI2NDcaOHYspU6bAzs4OCoUCEydOhI+PD15//XUAQI8ePeDl5YWRI0di6dKlSEpKwuzZs+Hv71+i4YNCWrfsx40bh7y8PNy8eROpqalITU3FzZs3oVKpMG7cOG0PR0REJErBwcFIT09Hp06d4OTkpF527NihrrNy5Ur07dsXgwcPRocOHeDo6Ii9e/eqt5uamuLQoUMwNTWFj48P3n33XYwaNQoLFizQKhaZIAiCNjtYWFjg/PnzRW6zi4iIQPv27fH06VOtAtCFUqmEjY0NEpL/1mr8hEpP+YzPUtC36tYl//VOulOptPqTSDpSKpVwqmGL9PT0cvs7XpgrhnxzDmaWVqU+Tu7TTOyc0K5cYy0vWnfju7i4FPvwnIKCAjg7O5dJUERERGVN3934FYnW3fjLli3DxIkTcfnyZXXZ5cuX8fHHH2P58uVlGhwREVFZ0fcEvYqkRC37qlWravyiycrKQps2bVCp0vPd8/PzUalSJbz33nsYOHBguQRKREREpVOiZL9q1apyDoOIiKh8Sbkbv0TJ3s/Pr7zjICIiKldl9bhcY1SqJ+gVys7ORm5urkaZsc1QJCIiEjutk31WVhZmzpyJnTt34smTJ0W2FxQUlElgREREZUnfr7itSLSejT9jxgycPn0awcHBkMvl+O677zB//nw4Oztj69at5REjERGRzmQy3RdjpXXL/uDBg9i6dSs6deqEMWPGoH379vDw8ICbmxu2b9+OESNGlEecREREVEpat+xTU1Ph7u4O4Pn4fGpqKgCgXbt2OHv2bNlGR0REVEYKZ+PrshgrrZO9u7s74uLiAAANGjTAzp07ATxv8f/7FX1EREQViZS78bVO9mPGjMGVK1cAAJ9++inWrVsHc3NzTJ48GdOnTy/zAImIiEg3Wo/ZT548Wf3vbt264datW4iIiICHhwe8vb3LNDgiIqKyIuXZ+DrdZw8Abm5ucHNzK4tYiIiIyo2uXfFGnOtLluzXrFlT4gNOmjSp1MEQERGVFz4u9xVWrlxZooPJZDImeyIiogqmRMm+cPZ9RWVWyQRmlbSea0ilUM3KzNAhSE52Hp9KqU9y/i3RK302lk1QilnpL+xvrHQesyciIjIGUu7GN+YfKkRERFQCbNkTEZEkyGSACWfjExERiZeJjslel30Njd34REREIleqZP/rr7/i3XffhY+PDx48eAAA2LZtG86dO1emwREREZUVvghHC3v27EHPnj1hYWGBP//8Ezk5OQCA9PR0LF68uMwDJCIiKguF3fi6LMZK62T/+eefY8OGDfj2229RuXJldXnbtm3xxx9/lGlwREREpDutJ+hFR0ejQ4cORcptbGyQlpZWFjERERGVOSk/G1/rlr2joyNiYmKKlJ87dw7u7u5lEhQREVFZK3zrnS6LsdI62Y8fPx4ff/wxLl68CJlMhocPH2L79u2YNm0aPvzww/KIkYiISGcmZbAYK6278T/99FOoVCp07doVT58+RYcOHSCXyzFt2jRMnDixPGIkIiIiHWid7GUyGf73v/9h+vTpiImJQWZmJry8vGBlZVUe8REREZUJKY/Zl/oJemZmZvDy8irLWIiIiMqNCXQbdzeB8WZ7rZN9586d//PBAqdPn9YpICIiIipbWif7pk2baqzn5eUhMjIS165dg5+fX1nFRUREVKbYja+FlStXFlseGBiIzMxMnQMiIiIqD3wRThl49913sWnTprI6HBEREZWRMnvFbXh4OMzNzcvqcERERGXq+fvsS988l1Q3/qBBgzTWBUFAYmIiLl++jDlz5pRZYERERGWJY/ZasLGx0Vg3MTGBp6cnFixYgB49epRZYERERFQ2tEr2BQUFGDNmDBo3boyqVauWV0xERERljhP0SsjU1BQ9evTg2+2IiMjoyMrgP2Ol9Wz8Ro0a4c6dO+URCxERUbkpbNnrshgrrZP9559/jmnTpuHQoUNITEyEUqnUWIiIiAg4e/Ys+vXrB2dnZ8hkMuzfv19j++jRoyGTyTSWXr16adRJTU3FiBEjoFAoYGtri7Fjx5bqmTYlTvYLFixAVlYWevfujStXrqB///6oVasWqlatiqpVq8LW1pbj+EREVGHpu2WflZWFJk2aYN26dS+t06tXLyQmJqqXH374QWP7iBEjcP36dZw4cQKHDh3C2bNnMWHCBK2vvcQT9ObPn48PPvgAv/zyi9YnISIiMrTC1rMu+2vD19cXvr6+/1lHLpfD0dGx2G03b97E0aNHcenSJbRs2RIAsHbtWvTu3RvLly+Hs7NziWMpcbIXBAEA0LFjxxIfnIiISGxeHLKWy+WQy+WlOtaZM2dgb2+PqlWrokuXLvj8889RrVo1AM8fVmdra6tO9ADQrVs3mJiY4OLFi3jzzTdLfB6txux1+UVERERkSGXVje/i4gIbGxv1EhQUVKp4evXqha1bt+LUqVP44osvEBYWBl9fXxQUFAAAkpKSYG9vr7FPpUqVYGdnh6SkJK3OpdV99vXr139lwk9NTdUqACIiIn0oqyfoJSQkQKFQqMtL26ofOnSo+t+NGzeGt7c36tatizNnzqBr166lD7QYWiX7+fPnF3mCHhERkZQoFAqNZF9W3N3dUb16dcTExKBr165wdHRESkqKRp38/Hykpqa+dJz/ZbRK9kOHDi3SpUBERGQMTGQynV6Eo8u+JXH//n08efIETk5OAAAfHx+kpaUhIiICLVq0AACcPn0aKpUKbdq00erYJU72HK8nIiJjpu/H5WZmZiImJka9HhcXh8jISNjZ2cHOzg7z58/H4MGD4ejoiNjYWMyYMQMeHh7o2bMnAKBhw4bo1asXxo8fjw0bNiAvLw8BAQEYOnSoVjPxAS0m6BXOxiciIqJXu3z5Mpo1a4ZmzZoBAKZMmYJmzZph7ty5MDU1xdWrV9G/f3/Ur18fY8eORYsWLfDrr79qzAHYvn07GjRogK5du6J3795o164dvvnmG61jKXHLXqVSaX1wIiKiCkPHCXraPhq/U6dO/9lQPnbs2CuPYWdnh9DQUO1OXAytX3FLRERkjEwgg4kOL7PRZV9DY7InIiJJKKtb74yR1i/CISIiIuPClj0REUmCvmfjVyRM9gbw7c4wrP3+FFKeKNGoXk18Mf1ttHittqHDEp2VIcdx6JcruH0vGebyymjduA7mTRyAem4Ohg5NNML/jEFw6GlcjU5A8mMlNgWNhW9Hb/X25d8dwf6Tf+BhShrMKpvC29MFn77fB835fS8T/I5rp6LfZ1+e2I2vZ3uPR2D2qn2YOc4XZ7bNRKN6NTF44jo8Ss0wdGii89sfMRj7dnsc2zgVe9f6I6+gAIMnrkPWsxxDhyYaT7Nz4eVRE4unvlXsdnfXGlg89S38sm0mDgR/DBcnOwz9JBiP/9b+fdxUFL/jVFIGTfZBQUFo1aoVrK2tYW9vj4EDByI6OtqQIZW79aGnMWrgGxjR3wcN3J2wYtZQWJqb4fufwg0dmujsXvMRhvd9HQ3rOqFR/VpYN/dd3E/6G1duJhg6NNHo6uOFT9/vg94dmxS7fVCPlujQyhNuNavD090JgZPeREZWNm7GPtBzpOLE77h2Cifo6bIYK4Mm+7CwMPj7++PChQs4ceIE8vLy0KNHD2RlZRkyrHKTm5ePyFsJ6NTaU11mYmKCjq09cSkqzoCRSYMyMxsAYGtjaeBIpCk3Lx/fHzgPhZUFvDxqGjocUeJ3/L+ZQKbuyi/VwlvvSufo0aMa6yEhIbC3t0dERAQ6dOhgoKjKz5O0TBQUqFDDzlqjvIadArfvJhsoKmlQqVT4bMUetGniDq+62j1mknRz4rdr+GDuFjzLzoNDNQV2rPoQ1WytDB2W6PA7Tv+lQk3QS09PB/D8iUHFycnJQU7OP2NRSqVSL3GR8Zu+dBdu3knE4W8+MXQoktO2eT2c3DIDqWlZ2P7TeUyYE4LD305B9Rd+9JJu+B1/Nd5nXwGoVCp88sknaNu2LRo1alRsnaCgINjY2KgXFxcXPUepm2q2VjA1NSkyGe9RqhL21cr+dYn03IxlO3Hs3DX8tH4iajpUNXQ4kmNpIUedWjXQolFtrPhsOCqZmiD00AVDhyUq/I6XjEkZLMaqwsTu7++Pa9eu4ccff3xpnVmzZiE9PV29JCQY1yQUs8qV0LSBC8Iu/TMJUaVS4eylv9CqcR0DRiZOgiBgxrKd+PnMVRxYPxFuNasbOiQCoFIJyM3NN3QYosDvOJVUhejGDwgIwKFDh3D27FnUqlXrpfXkcrnG24CM0UfDu+Cj+dvQrKErmr9WG8E//IKsZzkY0e91Q4cmOtOX7sTuYxHYvnw8rCzNkfz4+bCPwsocFuZmBo5OHLKe5iDu/iP1enziE1z76z5sFZaws6mCVVuOo2e7xrCvpkBqehZC9vyKpMfp6NelqeGCFhF+x7Ujk8l0el27Mb/q3aDJXhAETJw4Efv27cOZM2dQp474W7eDerTA47RMLP76Z6Q8yUDj+jWxe40/u/HLwaY95wAA/T5Yo1H+1dwRGN6XP67KwpVb8Rgc8JV6PXDNfgDAkN6t8cX0IYi5l4JdhzchNT0TVW2qoGkDV+xfPwme7k4Gilhc+B3Xjgxav7iuyP7GSiYY8EX1H330EUJDQ3HgwAF4ev5zO5qNjQ0sLCxeub9SqYSNjQ2Sn6RDoWCy1AcDfl0kKyefr5fWJ3mlCjO6KQlKpRKO1W2Rnl5+f8cLc8U3Z27Awqr0E0OfZWZgQievco21vBj0Wx0cHIz09HR06tQJTk5O6mXHjh2GDIuIiEhUDN6NT0REpC/G3BWviwoxQY+IiKi88T57IiIiEi227ImISBJ46x0REZHI6foUPGPuCjfm2ImIiKgE2LInIiJJYDc+ERGRyEn5CXrsxiciIhI5tuyJiEgS2I1PREQkclKejc9kT0REkiDllr0x/1AhIiKiEmDLnoiIJEHKs/GZ7ImISBL4IhwiIiISLbbsiYhIEkwgg4kOnfG67GtoTPZERCQJ7MYnIiIi0WLLnoiIJEH2///psr+xYrInIiJJYDc+ERERiRZb9kREJAkyHWfjsxufiIiogpNyNz6TPRERSYKUkz3H7ImIiMrB2bNn0a9fPzg7O0Mmk2H//v0a2wVBwNy5c+Hk5AQLCwt069YNt2/f1qiTmpqKESNGQKFQwNbWFmPHjkVmZqbWsTDZExGRJMjK4D9tZGVloUmTJli3bl2x25cuXYo1a9Zgw4YNuHjxIqpUqYKePXsiOztbXWfEiBG4fv06Tpw4gUOHDuHs2bOYMGGC1tfObnwiIpIEE9nzRZf9teHr6wtfX99itwmCgFWrVmH27NkYMGAAAGDr1q1wcHDA/v37MXToUNy8eRNHjx7FpUuX0LJlSwDA2rVr0bt3byxfvhzOzs4lj1270ImIiKRNqVRqLDk5OVofIy4uDklJSejWrZu6zMbGBm3atEF4eDgAIDw8HLa2tupEDwDdunWDiYkJLl68qNX5mOyJiEgSyqob38XFBTY2NuolKChI61iSkpIAAA4ODhrlDg4O6m1JSUmwt7fX2F6pUiXY2dmp65QUu/GJiEgSymo2fkJCAhQKhbpcLpfrGFn5Y8ueiIhICwqFQmMpTbJ3dHQEACQnJ2uUJycnq7c5OjoiJSVFY3t+fj5SU1PVdUqKyZ6IiCRBBl278stOnTp14OjoiFOnTqnLlEolLl68CB8fHwCAj48P0tLSEBERoa5z+vRpqFQqtGnTRqvzsRufiIgkQd+z8TMzMxETE6Nej4uLQ2RkJOzs7ODq6opPPvkEn3/+OerVq4c6depgzpw5cHZ2xsCBAwEADRs2RK9evTB+/Hhs2LABeXl5CAgIwNChQ7WaiQ8w2RMREZWLy5cvo3Pnzur1KVOmAAD8/PwQEhKCGTNmICsrCxMmTEBaWhratWuHo0ePwtzcXL3P9u3bERAQgK5du8LExASDBw/GmjVrtI5FJgiCoPslGYZSqYSNjQ2Sn6RrTJag8mPEXxejlZOvMnQIkiKvxNFNfVIqlXCsbov09PL7O16YK45E3EUVq9KfIytTCd8Wtcs11vLClj0REUmClJ+Nz2RPRESSIPv/RZf9jRX7q4iIiESOLXsiIpIEE8hgokNfvIkRt+1Fkeyz8wpglldg6DAkwdSYB62MFCeM6Vf60zxDhyApGXr8vNmNT0RERKIlipY9ERHRK0m4ac9kT0REkqDrQ2/L9oG5+sVufCIiIpFjy56IiKRBx4fqGHHDnsmeiIikQcJD9uzGJyIiEju27ImISBok3LRnsiciIkmQ8mx8JnsiIpIEKb/1jmP2REREIseWPRERSYKEh+yZ7ImISCIknO3ZjU9ERCRybNkTEZEkcDY+ERGRyHE2PhEREYkWW/ZERCQJEp6fx2RPREQSIeFsz258IiIikWPLnoiIJIGz8YmIiEROyrPxmeyJiEgSJDxkzzF7IiIisWPLnoiIpEHCTXsmeyIikgQpT9BjNz4REZHIsWVPRESSwNn4REREIifhIXt24xMREYkdW/ZERCQNEm7aM9kTEZEkcDY+ERERiRZb9kREJAmcjU9ERCRyEh6yZ7InIiKJkHC255g9ERFROQgMDIRMJtNYGjRooN6enZ0Nf39/VKtWDVZWVhg8eDCSk5PLJRYmeyIikgRZGfynrddeew2JiYnq5dy5c+ptkydPxsGDB7Fr1y6EhYXh4cOHGDRoUFleshq78YmISBp0nKBXmm78SpUqwdHRsUh5eno6Nm7ciNDQUHTp0gUAsHnzZjRs2BAXLlzA66+/rkOgRbFlT0REpAWlUqmx5OTkvLTu7du34ezsDHd3d4wYMQLx8fEAgIiICOTl5aFbt27qug0aNICrqyvCw8PLPGa27MtR+J8xCA49javRCUh+rMSmoLHw7eit3r78uyPYf/IPPExJg1llU3h7uuDT9/ug+Wu1DRe0yGRmZWPJNz/j8NmreJyaiUb1a2LR5MFo5uVm6NBEaWXIcRz65Qpu30uGubwyWjeug3kTB6Cem4OhQxOF9dtP4tjZKMTGp8BcXhnNX6uNme/3RV1Xe3Wdew8eY3HwT7gcFYfcvHx0aN0AgZMGoYadtQEjrxjKan6ei4uLRvm8efMQGBhYpH6bNm0QEhICT09PJCYmYv78+Wjfvj2uXbuGpKQkmJmZwdbWVmMfBwcHJCUl6RBl8Qzasg8ODoa3tzcUCgUUCgV8fHxw5MgRQ4ZUpp5m58LLoyYWT32r2O3urjWweOpb+GXbTBwI/hguTnYY+kkwHv+dqedIxWty0A8IuxSNdXNH4sz3n6JTmwZ4a9I6JKakGTo0UfrtjxiMfbs9jm2cir1r/ZFXUIDBE9ch69nLWz5UchcjYzFyYFvsXf8xti5/H/kFBRg1/Ws8/f/P9+mzHIya/jVkMhm2r/wQu76aiLy8Aoz77DuoVCoDR18ByMpgAZCQkID09HT1MmvWrGJP5+vri7fffhve3t7o2bMnDh8+jLS0NOzcubMcL7J4Bk32tWrVwpIlSxAREYHLly+jS5cuGDBgAK5fv27IsMpMVx8vfPp+H/Tu2KTY7YN6tESHVp5wq1kdnu5OCJz0JjKysnEz9oGeIxWnZ9m5OHTmCub6D4BPMw+4u9TAjHG9UadWdYTsO/fqA5DWdq/5CMP7vo6GdZ3QqH4trJv7Lu4n/Y0rNxMMHZoobFn2Pt7ybY36dRzh5VETyz4dhofJfyPqr/sAgMvX7uJ+UiqWfToMDdyd0cDdGctnDUNU9H2c/yPGwNGLR2EDtXCRy+Ul2s/W1hb169dHTEwMHB0dkZubi7S0NI06ycnJxY7x68qgyb5fv37o3bs36tWrh/r162PRokWwsrLChQsXDBmWQeTm5eP7A+ehsLKAl0dNQ4cjCgUFKhQUqCA30xytMpeb4eKVOwaKSlqUmdkAAFsbSwNHIk4Zmc8AALbWzz/f3Lx8yCCDWeV/vvNys8owkclwOYrfeUPMxv+3zMxMxMbGwsnJCS1atEDlypVx6tQp9fbo6GjEx8fDx8dH10stosKM2RcUFGDXrl3IysoqlwutqE78dg0fzN2CZ9l5cKimwI5VH6KarZWhwxIFqyrmaNmoNlZsPob6tR1Rw84ae09E4PK1ONSpVcPQ4YmeSqXCZyv2oE0Td3jVdTZ0OKKjUqmw8KsDaNmoDjzdnQAAzbzcYGlhhi++Pojp4/tAEAR88c3PKFCpkJKqNHDEhqfvx+VOmzYN/fr1g5ubGx4+fIh58+bB1NQUw4YNg42NDcaOHYspU6bAzs4OCoUCEydOhI+PT5nPxAcqQLKPioqCj48PsrOzYWVlhX379sHLy6vYujk5ORqzHpVK4//ytm1eDye3zEBqWha2/3QeE+aE4PC3U1Cdk2nKxLp5I/HJolB4958DU1MTeNevhTe7t8DVW+xWLm/Tl+7CzTuJOPzNJ4YORZTmrtqL6LhE7Fo7UV1WzdYKXwX6Yc7K3QjZew4mMhn6dW2GRvVrwUTGm6/07f79+xg2bBiePHmCGjVqoF27drhw4QJq1Hje2Fi5ciVMTEwwePBg5OTkoGfPnli/fn25xCITBEEolyOXUG5uLuLj45Geno7du3fju+++Q1hYWLEJPzAwEPPnzy9Sfi8pFQqFQh/hlprTGx8XmY1fnDeGLMTQvq9j0qjueopMO6ZG+iaIrGc5yMzKhkN1G4yfvRlZz3IQ+uUHhg6rRCqZGt9nPmPZThwOi8LPX38Mt5rVDR2OVtKf5hk6hFeau2oPTv52HTvW+MPFqVqxdVLTMlHJ1BQKawu0enMexr3TEe8P7aLnSF8tQ6lEfdcaSE9PL7e/40qlEjY2Nrh6JxnW1qU/R0aGEt7uDuUaa3kx+E89MzMzeHh4oEWLFggKCkKTJk2wevXqYuvOmjVLYwZkQoL4WmcqlYDc3HxDhyE6VSzkcKhugzTlU/xy8RZ6tW9s6JBESRAEzFi2Ez+fuYoD6ycaXaKv6ARBwNxVe3D8XBS2r/zwpYkeAOxsraCwtsD5P27jSVomur3RSI+RVlBlNBvfGBm8G/9FKpXqpQ8okMvlJZ71WBFkPc1B3P1H6vX4xCe49td92CosYWdTBau2HEfPdo1hX02B1PQshOz5FUmP09GvS1PDBS0ypy/cBAQBdd0cEHf/EeZ/dQD13OwxrG/Zj4kRMH3pTuw+FoHty8fDytIcyY+fD7UprMxhYW5m4OiM39xVe3Dg5B/4ZtF7sLKQ49GT55+vtZU5zOXPP99dR36Hh6s97Gyt8Mf1u1jw1X6893YHjXvxpUrXSXa6TtAzJIMm+1mzZsHX1xeurq7IyMhAaGgozpw5g2PHjhkyrDJz5VY8Bgd8pV4PXLMfADCkd2t8MX0IYu6lYNfhTUhNz0RVmypo2sAV+9dPUk+2Id1lZD7D5xsOIjElDbaKKujbqQk++6AvKlcyNXRoorRpz/NbGvt9sEaj/Ku5IzCcP7B09v2B8wCAYZ9ojusumzkUb/m2BgDciU/B0m9+RnrGU9R0tIP/u90w9u2Oeo+VKhaDjtmPHTsWp06dQmJiImxsbODt7Y2ZM2eie/eSjVcXjsMYw5i9WBjrmL0xM8Yxe2NmDGP2YqLPMftrcSmw1uEcGUolGtWxN8oxe4O27Ddu3GjI0xMRkYRI+HX2hp+gR0REROWrwk3QIyIiKg/6fqhORcJkT0REEiHdjnx24xMREYkcW/ZERCQJ7MYnIiISOel24rMbn4iISPTYsiciIklgNz4REZHI8dn4REREYifhQXuO2RMREYkcW/ZERCQJEm7YM9kTEZE0SHmCHrvxiYiIRI4teyIikgTOxiciIhI7CQ/asxufiIhI5NiyJyIiSZBww57JnoiIpIGz8YmIiEi02LInIiKJ0G02vjF35DPZExGRJLAbn4iIiESLyZ6IiEjk2I1PRESSIOVufCZ7IiKSBCk/Lpfd+ERERCLHlj0REUkCu/GJiIhETsqPy2U3PhERkcixZU9ERNIg4aY9kz0REUkCZ+MTERGRaLFlT0REksDZ+ERERCIn4SF7duMTEZFEyMpgKYV169ahdu3aMDc3R5s2bfD777/rdh2lwGRPRERUTnbs2IEpU6Zg3rx5+OOPP9CkSRP07NkTKSkpeo2DyZ6IiCRBVgb/aWvFihUYP348xowZAy8vL2zYsAGWlpbYtGlTOVzhyzHZExGRJBRO0NNl0UZubi4iIiLQrVs3dZmJiQm6deuG8PDwMr66/2bUE/QEQQAAZGQoDRyJdJga83RUI1XJlJ+5PmU8zTN0CJKSmZEB4J+/5+VJqdQtVxTu/+Jx5HI55HJ5kfqPHz9GQUEBHBwcNModHBxw69YtnWLRllEn+4z//5I0qlfbsIEQEZFOMjIyYGNjUy7HNjMzg6OjI+rVcdH5WFZWVnBx0TzOvHnzEBgYqPOxy5NRJ3tnZ2ckJCTA2toaMiNqcSqVSri4uCAhIQEKhcLQ4UgCP3P94uetf8b6mQuCgIyMDDg7O5fbOczNzREXF4fc3FydjyUIQpF8U1yrHgCqV68OU1NTJCcna5QnJyfD0dFR51i0YdTJ3sTEBLVq1TJ0GKWmUCiM6n9KMeBnrl/8vPXPGD/z8mrR/5u5uTnMzc3L/Tz/ZmZmhhYtWuDUqVMYOHAgAEClUuHUqVMICAjQayxGneyJiIgqsilTpsDPzw8tW7ZE69atsWrVKmRlZWHMmDF6jYPJnoiIqJy88847ePToEebOnYukpCQ0bdoUR48eLTJpr7wx2RuAXC7HvHnzXjrOQ2WPn7l+8fPWP37mFVdAQIDeu+1fJBP0cb8DERERGQwfqkNERCRyTPZEREQix2RPREQkckz2REREIsdkbwAV4d3GUnH27Fn069cPzs7OkMlk2L9/v6FDErWgoCC0atUK1tbWsLe3x8CBAxEdHW3osEQrODgY3t7e6gfp+Pj44MiRI4YOiyogJns9qyjvNpaKrKwsNGnSBOvWrTN0KJIQFhYGf39/XLhwASdOnEBeXh569OiBrKwsQ4cmSrVq1cKSJUsQERGBy5cvo0uXLhgwYACuX79u6NCoguGtd3rWpk0btGrVCl999RWA549OdHFxwcSJE/Hpp58aODpxk8lk2Ldvn/qxlVT+Hj16BHt7e4SFhaFDhw6GDkcS7OzssGzZMowdO9bQoVAFwpa9HlWkdxsT6UN6ejqA5wmIyldBQQF+/PFHZGVlwcfHx9DhUAXDJ+jpUUV6tzFReVOpVPjkk0/Qtm1bNGrUyNDhiFZUVBR8fHyQnZ0NKysr7Nu3D15eXoYOiyoYJnsiKhf+/v64du0azp07Z+hQRM3T0xORkZFIT0/H7t274efnh7CwMCZ80sBkr0cV6d3GROUpICAAhw4dwtmzZ436NdTGwMzMDB4eHgCAFi1a4NKlS1i9ejW+/vprA0dGFQnH7PXo3+82LlT4bmOOsZEYCIKAgIAA7Nu3D6dPn0adOnUMHZLkqFQq5OTkGDoMqmDYstezivJuY6nIzMxETEyMej0uLg6RkZGws7ODq6urASMTJ39/f4SGhuLAgQOwtrZGUlISAMDGxgYWFhYGjk58Zs2aBV9fX7i6uiIjIwOhoaE4c+YMjh07ZujQqILhrXcG8NVXX2HZsmXqdxuvWbMGbdq0MXRYonTmzBl07ty5SLmfnx9CQkL0H5DIyWSyYss3b96M0aNH6zcYCRg7dixOnTqFxMRE2NjYwNvbGzNnzkT37t0NHRpVMEz2REREIscxeyIiIpFjsiciIhI5JnsiIiKRY7InIiISOSZ7IiIikWOyJyIiEjkmeyIiIpFjsifS0ejRozFw4ED1eqdOnfDJJ5/oPY4zZ85AJpMhLS3tpXVkMhn2799f4mMGBgaiadOmOsV19+5dyGQyREZG6nQcIio9JnsSpdGjR0Mmk0Emk6lfFLJgwQLk5+eX+7n37t2LhQsXlqhuSRI0EZGu+Gx8Eq1evXph8+bNyMnJweHDh+Hv74/KlStj1qxZRerm5ubCzMysTM5rZ2dXJschIiorbNmTaMnlcjg6OsLNzQ0ffvghunXrhp9++gnAP13vixYtgrOzMzw9PQEACQkJGDJkCGxtbWFnZ4cBAwbg7t276mMWFBRgypQpsLW1RbVq1TBjxgy8+MTpF7vxc3JyMHPmTLi4uEAul8PDwwMbN27E3bt31c/tr1q1KmQymfr58SqVCkFBQahTpw4sLCzQpEkT7N69W+M8hw8fRv369WFhYYHOnTtrxFlSM2fORP369WFpaQl3d3fMmTMHeXl5Rep9/fXXcHFxgaWlJYYMGYL09HSN7d999x0aNmwIc3NzNGjQAOvXr9c6FiIqP0z2JBkWFhbIzc1Vr586dQrR0dE4ceIEDh06hLy8PPTs2RPW1tb49ddf8dtvv8HKygq9evVS7/fll18iJCQEmzZtwrlz55Camop9+/b953lHjRqFH374AWvWrMHNmzfx9ddfw8rKCi4uLtizZw8AIDo6GomJiVi9ejUAICgoCFu3bsWGDRtw/fp1TJ48Ge+++y7CwsIAPP9RMmjQIPTr1w+RkZEYN24cPv30U60/E2tra4SEhODGjRtYvXo1vv32W6xcuVKjTkxMDHbu3ImDBw/i6NGj+PPPP/HRRx+pt2/fvh1z587FokWLcPPmTSxevBhz5szBli1btI6HiMqJQCRCfn5+woABAwRBEASVSiWcOHFCkMvlwrRp09TbHRwchJycHPU+27ZtEzw9PQWVSqUuy8nJESwsLIRjx44JgiAITk5OwtKlS9Xb8/LyhFq1aqnPJQiC0LFjR+Hjjz8WBEEQoqOjBQDCiRMnio3zl19+EQAIf//9t7osOztbsLS0FM6fP69Rd+zYscKwYcMEQRCEWbNmCV5eXhrbZ86cWeRYLwIg7Nu376Xbly1bJrRo0UK9Pm/ePMHU1FS4f/++uuzIkSOCiYmJkJiYKAiCINStW1cIDQ3VOM7ChQsFHx8fQRAEIS4uTgAg/Pnnny89LxGVL47Zk2gdOnQIVlZWyMvLg0qlwvDhwxEYGKje3rhxY41x+itXriAmJgbW1tYax8nOzkZsbCzS09ORmJio8TriSpUqoWXLlkW68gtFRkbC1NQUHTt2LHHcMTExePr0aZHXlObm5qJZs2YAgJs3bxZ5LbKPj0+Jz1Fox44dWLNmDWJjY5GZmYn8/HwoFAqNOq6urqhZs6bGeVQqFaKjo2FtbY3Y2FiMHTsW48ePV9fJz8+HjY2N1vEQUflgsifR6ty5M4KDg2FmZgZnZ2dUqqT5da9SpYrGemZmJlq0aIHt27cXOVaNGjVKFYOFhYXW+2RmZgIAfv75Z40kCzyfh1BWwsPDMWLECMyfPx89e/aEjY0NfvzxR3z55Zdax/rtt98W+fFhampaZrESkW6Y7Em0qlSpAg8PjxLXb968OXbs2AF7e/sirdtCTk5OuHjxIjp06ADgeQs2IiICzZs3L7Z+48aNoVKpEBYWhm7duhXZXtizUFBQoC7z8vKCXC5HfHz8S3sEGjZsqJ5sWOjChQuvvsh/OX/+PNzc3PC///1PXXbv3r0i9eLj4/Hw4UM4Ozurz2NiYgJPT084ODjA2dkZd+7cwYgRI7Q6PxHpDyfoEf2/ESNGoHr16hgwYAB+/fVXxMXF4cyZM5g0aRLu378PAPj444+xZMkS7N+/H7du3cJHH330n/fI165dG35+fnjvvfewf/9+9TF37twJAHBzc4NMJsOhQ4fw6NEjZGZmwtraGtOmTcPkyZOxZcsWxMbG4o8//sDatWvVk94++OAD3L59G9OnT0d0dDRCQ0MREhKi1fXWq1cP8fHx+PHHHxEbG4s1a9YUO9nQ3Nwcfn5+uHLlCn799VdMmjQJQ4YMgaOjIwBg/vz5CAoKwpo1a/DXX38hKioKmzdvxooVK7SKh4jKD5M90f+ztLTE2bNn4erqikGDBqFhw4YYO3YssrOz1S39qVOnYuTIkfDz84OPjw+sra3x5ptv/udxg4OD8dZbb+Gjjz5CgwYNMH78eGRlZQEAatasifnz5+PTTz+Fg4MDAgICAAALFy7EnDlzEBQUhIYNG6JXr174+eefUadOHQDPx9H37NmD/fv3o0mTJtiwYQMWL16s1fX2798fkydPRkBAAJo2bYrz589jzpw5Rep5eHhg0KBB6N27N3r06AFvb2+NW+vGjRuH7777Dps3b0bjxo3RsWNHhISEqGMlIsOTCS+bWURERESiwJY9ERGRyDHZExERiRyTPRERkcgx2RMREYkckz0REZHIMdkTERGJHJM9ERGRyDHZExERiRyTPRERkcgx2RMREYkckz0REZHIMdkTERGJ3P8BhoWxQ0nH5H4AAAAASUVORK5CYII=\n"},"metadata":{}}],"execution_count":69},{"cell_type":"code","source":"# Saving the best model to hub\ntrainer2.save_model(\"best_model\")\ntrainer2.push_to_hub(\"Vyke2000/BERT_v2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T10:33:07.150917Z","iopub.execute_input":"2025-01-31T10:33:07.151274Z","iopub.status.idle":"2025-01-31T10:33:17.428190Z","shell.execute_reply.started":"2025-01-31T10:33:07.151245Z","shell.execute_reply":"2025-01-31T10:33:17.427183Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84731127ed56498ba66e172b9ede4932"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/5.30k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21c1a4c3df494c01b2a7fc451753962f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21f1c2e37ab6418aa70459d26ec92f32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1738318837.f92e2c842e43.31.0:   0%|          | 0.00/486 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a783707290c4f77a2cebef60a9b99b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1738318996.f92e2c842e43.31.1:   0%|          | 0.00/486 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45cd5a14981f47488941c5642fd6d540"}},"metadata":{}},{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Vyke2000/tmp/commit/fe3d45a1a966ce03ed1ae6f0c10a201637d619f6', commit_message='Vyke2000/BERT_v2', commit_description='', oid='fe3d45a1a966ce03ed1ae6f0c10a201637d619f6', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Vyke2000/tmp', endpoint='https://huggingface.co', repo_type='model', repo_id='Vyke2000/tmp'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":70}]}