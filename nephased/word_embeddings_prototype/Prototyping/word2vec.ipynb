{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a378a1b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-27T11:08:42.576224Z",
     "iopub.status.busy": "2025-05-27T11:08:42.575330Z",
     "iopub.status.idle": "2025-05-27T11:08:44.419524Z",
     "shell.execute_reply": "2025-05-27T11:08:44.418663Z"
    },
    "papermill": {
     "duration": 1.851024,
     "end_time": "2025-05-27T11:08:44.421175",
     "exception": false,
     "start_time": "2025-05-27T11:08:42.570151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/nepsa/NepSA.csv\n",
      "/kaggle/input/pretrained-fasttext/pretrained_word2vec/pretrained_word2vec.txt\n",
      "/kaggle/input/pretrained-fasttext/pretrained_fasttext/pretrained_fasttext/pretrained.fast_text.wv.vectors_vocab.npy\n",
      "/kaggle/input/pretrained-fasttext/pretrained_fasttext/pretrained_fasttext/pretrained.fast_text.trainables.vectors_ngrams_lockf.npy\n",
      "/kaggle/input/pretrained-fasttext/pretrained_fasttext/pretrained_fasttext/pretrained.fast_text.wv.vectors.npy\n",
      "/kaggle/input/pretrained-fasttext/pretrained_fasttext/pretrained_fasttext/pretrained.fast_text.trainables.syn1neg.npy\n",
      "/kaggle/input/pretrained-fasttext/pretrained_fasttext/pretrained_fasttext/pretrained.fast_text.trainables.vectors_vocab_lockf.npy\n",
      "/kaggle/input/pretrained-fasttext/pretrained_fasttext/pretrained_fasttext/pretrained.fast_text.wv.vectors_ngrams.npy\n",
      "/kaggle/input/pretrained-fasttext/pretrained_fasttext/pretrained_fasttext/pretrained.fast_text\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65ab5363",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T11:08:44.429437Z",
     "iopub.status.busy": "2025-05-27T11:08:44.429043Z",
     "iopub.status.idle": "2025-05-27T11:08:44.508732Z",
     "shell.execute_reply": "2025-05-27T11:08:44.507613Z"
    },
    "papermill": {
     "duration": 0.085339,
     "end_time": "2025-05-27T11:08:44.510234",
     "exception": false,
     "start_time": "2025-05-27T11:08:44.424895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4707 entries, 0 to 4706\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Text    4707 non-null   object\n",
      " 1   Target  4707 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 73.7+ KB\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "df= pd.read_csv(\"/kaggle/input/nepsa/NepSA.csv\")\n",
    "df_copy= df.copy()\n",
    "df.info()\n",
    "\n",
    "scratch_output = \"./scratch/\"\n",
    "finetuned_output = \"./output\"\n",
    "Path(scratch_output).mkdir()\n",
    "Path(finetuned_output).mkdir()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9e89b4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T11:08:44.518374Z",
     "iopub.status.busy": "2025-05-27T11:08:44.518091Z",
     "iopub.status.idle": "2025-05-27T11:08:47.261565Z",
     "shell.execute_reply": "2025-05-27T11:08:47.260685Z"
    },
    "papermill": {
     "duration": 2.749472,
     "end_time": "2025-05-27T11:08:47.263246",
     "exception": false,
     "start_time": "2025-05-27T11:08:44.513774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenizing using nltk and creating a corpus for models to train on\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sentences= df_copy['Text'].apply(lambda x: word_tokenize(x)).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4af905",
   "metadata": {
    "papermill": {
     "duration": 0.003062,
     "end_time": "2025-05-27T11:08:47.269871",
     "exception": false,
     "start_time": "2025-05-27T11:08:47.266809",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Word2Vec scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "238336d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T11:08:47.277691Z",
     "iopub.status.busy": "2025-05-27T11:08:47.277199Z",
     "iopub.status.idle": "2025-05-27T11:10:21.782326Z",
     "shell.execute_reply": "2025-05-27T11:10:21.781392Z"
    },
    "papermill": {
     "duration": 94.51305,
     "end_time": "2025-05-27T11:10:21.786179",
     "exception": false,
     "start_time": "2025-05-27T11:08:47.273129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24787000.0\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "scratch = Word2Vec(sentences, vector_size= 300,sg=1 ,negative=10 ,window= 15, min_count=3,alpha=0.0025, epochs=200, workers=4, seed= 42, compute_loss=True)  #sg=1 means using Skip-gram\n",
    "print(scratch.get_latest_training_loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b493ccf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T11:10:21.794224Z",
     "iopub.status.busy": "2025-05-27T11:10:21.793731Z",
     "iopub.status.idle": "2025-05-27T11:10:21.827692Z",
     "shell.execute_reply": "2025-05-27T11:10:21.826833Z"
    },
    "papermill": {
     "duration": 0.039699,
     "end_time": "2025-05-27T11:10:21.829268",
     "exception": false,
     "start_time": "2025-05-27T11:10:21.789569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "दलाल: [('गोरू', 0.6033902764320374), ('घुसिया', 0.5901913046836853), ('पापी', 0.5852494239807129), ('भारतिय', 0.5696837306022644), ('भुमाफिया', 0.5645279884338379), ('संसद', 0.5618158578872681), ('नपाएर', 0.5473347902297974), ('रहने', 0.547138512134552), ('सम्बन्ध', 0.5425519347190857), ('लाइक', 0.5418401956558228)]\n",
      "मुजि: [('नगेन्द्र', 0.711967945098877), ('हरामि', 0.6714503169059753), ('रण्डि', 0.6606051921844482), ('चम्चा', 0.6590189337730408), ('खालि', 0.658369243144989), ('बादी', 0.6579492688179016), ('प्रचन्डे', 0.6545289754867554), ('आय', 0.6520548462867737), ('लामो', 0.6494603157043457), ('बोल्नै', 0.6484158039093018)]\n",
      "रन्डि: [('रन्दि', 0.8004626631736755), ('राडी', 0.7874512076377869), ('मास्टर', 0.7845054864883423), ('बन', 0.7817702889442444), ('तेइ', 0.776989758014679), ('चिक्ने', 0.7758449912071228), ('जादा', 0.772700309753418), ('पढ्ने', 0.7706379294395447), ('बान', 0.7697343230247498), ('चिरि', 0.7646850943565369)]\n",
      "चिक्ने: [('मया', 0.9028002023696899), ('मास्टर', 0.856492280960083), ('खुला', 0.831656813621521), ('चिरि', 0.8166017532348633), ('खुर्सानि', 0.7964403629302979), ('दल्लनु', 0.7886158227920532), ('जाठा', 0.7859798073768616), ('कन्डम', 0.7810840606689453), ('उल्टो', 0.7794399261474609), ('छोरो', 0.7773451805114746)]\n",
      "ठोक्ने: [('चलाउनु', 0.8740246891975403), ('युटुबे', 0.8137953281402588), ('त्यहीँ', 0.8135911226272583), ('झुन्ड्याएर', 0.7951729893684387), ('कालोमोसो', 0.7852705121040344), ('जहा', 0.7646588087081909), ('भेटिन्छ', 0.7585576176643372), ('घुमाउनु', 0.7456748485565186), ('खानु', 0.7427929043769836), ('भेट्यो', 0.7424158453941345)]\n",
      "बलात्कारी: [('नजिक', 0.8386161923408508), ('पसल', 0.8364304900169373), ('गेट', 0.8338086605072021), ('सकेको', 0.8300403952598572), ('बहिष्कार', 0.8106518983840942), ('बेस्या', 0.8022472858428955), ('भरि', 0.7982656359672546), ('बजार', 0.7961803674697876), ('केस', 0.7912651300430298), ('ओई', 0.7900994420051575)]\n",
      "माचिक्ने: [('खा', 0.7636635899543762), ('राडी', 0.7445529103279114), ('राडि', 0.74214106798172), ('लादो', 0.7359866499900818), ('पख', 0.7289491295814514), ('बोल्दा', 0.728051483631134), ('नलाग्ने', 0.7274912595748901), ('रन्दि', 0.7196236252784729), ('बस्छ', 0.7174572944641113), ('काग', 0.7163844108581543)]\n",
      "Similarity between ठोक and हान्नु: 0.6542066931724548\n"
     ]
    }
   ],
   "source": [
    "print(f\"दलाल: {scratch.wv.most_similar('दलाल')}\")\n",
    "print(f\"मुजि: {scratch.wv.most_similar('मुजि')}\")\n",
    "print(f\"रन्डि: {scratch.wv.most_similar('रन्डि')}\")\n",
    "print(f\"चिक्ने: {scratch.wv.most_similar('चिक्ने')}\")\n",
    "print(f\"ठोक्ने: {scratch.wv.most_similar('ठोक्ने')}\")\n",
    "print(f\"बलात्कारी: {scratch.wv.most_similar('बलात्कारी')}\")\n",
    "print(f\"माचिक्ने: {scratch.wv.most_similar('माचिक्ने')}\")\n",
    "print(f\"Similarity between ठोक and हान्नु: {scratch.wv.similarity('ठोक', 'हान्नु')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3752d063",
   "metadata": {
    "papermill": {
     "duration": 0.003225,
     "end_time": "2025-05-27T11:10:21.837246",
     "exception": false,
     "start_time": "2025-05-27T11:10:21.834021",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Saving Word2Vec will be done in txt as Word2Vec doesn't make sub word vectors unlike fasttext. So vectors saved as txt file will suffice.Furthermore the pre-trained Word2Vec model itself is a txt file and not a full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab6bea7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T11:10:21.845099Z",
     "iopub.status.busy": "2025-05-27T11:10:21.844773Z",
     "iopub.status.idle": "2025-05-27T11:10:22.350927Z",
     "shell.execute_reply": "2025-05-27T11:10:22.350038Z"
    },
    "papermill": {
     "duration": 0.511805,
     "end_time": "2025-05-27T11:10:22.352375",
     "exception": false,
     "start_time": "2025-05-27T11:10:21.840570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scratch.wv.save_word2vec_format(os.path.join(scratch_output, 'scratch.txt'), binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c547521e",
   "metadata": {
    "papermill": {
     "duration": 0.003155,
     "end_time": "2025-05-27T11:10:22.359081",
     "exception": false,
     "start_time": "2025-05-27T11:10:22.355926",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Pre-trained Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "542fb212",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T11:10:22.366846Z",
     "iopub.status.busy": "2025-05-27T11:10:22.366386Z",
     "iopub.status.idle": "2025-05-27T11:12:11.748794Z",
     "shell.execute_reply": "2025-05-27T11:12:11.747854Z"
    },
    "papermill": {
     "duration": 109.388185,
     "end_time": "2025-05-27T11:12:11.750476",
     "exception": false,
     "start_time": "2025-05-27T11:10:22.362291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "pretrained_input = \"/kaggle/input/pretrained-fasttext/pretrained_word2vec/pretrained_word2vec.txt\"\n",
    "\n",
    "pretrained = KeyedVectors.load_word2vec_format(pretrained_input, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580b3208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T10:19:01.885327Z",
     "iopub.status.busy": "2025-05-27T10:19:01.884950Z",
     "iopub.status.idle": "2025-05-27T10:19:02.204524Z",
     "shell.execute_reply": "2025-05-27T10:19:02.203202Z",
     "shell.execute_reply.started": "2025-05-27T10:19:01.885301Z"
    },
    "papermill": {
     "duration": 0.003126,
     "end_time": "2025-05-27T11:12:11.757651",
     "exception": false,
     "start_time": "2025-05-27T11:12:11.754525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adb246c5",
   "metadata": {
    "papermill": {
     "duration": 0.002923,
     "end_time": "2025-05-27T11:12:11.763831",
     "exception": false,
     "start_time": "2025-05-27T11:12:11.760908",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fine-Tuned Word2Vec\n",
    "The pretrained model is a txt file and finetuning without a full model doesn't sound convincing. However a full model from [NPVec1](https://github.com/nowalab/nepali-word-embeddings), specifically the tokenized and stemmed one which fits required case the most doesn't load at all. That's why the alternative being the 300 dimensional Word2Vec [model](https://ieee-dataport.org/open-access/300-dimensional-word-embeddings-nepali-language) which is only a text file of the word vectors. The finetuning procedure will be as stated in this [site](https://czarrar.github.io/Gensim-Word2Vec/) and another [site](https://datascience.stackexchange.com/questions/97568/fine-tuning-pre-trained-word2vec-model-with-gensim-4-0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af09a8a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T11:12:11.771454Z",
     "iopub.status.busy": "2025-05-27T11:12:11.771157Z",
     "iopub.status.idle": "2025-05-27T11:14:29.567446Z",
     "shell.execute_reply": "2025-05-27T11:14:29.566579Z"
    },
    "papermill": {
     "duration": 137.80325,
     "end_time": "2025-05-27T11:14:29.570227",
     "exception": false,
     "start_time": "2025-05-27T11:12:11.766977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6063188, 9137400)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned = Word2Vec(vector_size = 300,sg=1 ,negative=10 ,window= 15, min_count=3,alpha=0.0025, epochs=200, workers=4, seed= 42)\n",
    "finetuned.build_vocab(sentences)\n",
    "\n",
    "# Adding pre-trained model vocabulary\n",
    "finetuned.build_vocab([list(pretrained.key_to_index.keys())], update=True)\n",
    "\n",
    "# Ensuring all the words in the vocabulary are updated during finetuning with vectors of ones\n",
    "vocab_size = len(finetuned.wv)\n",
    "finetuned.wv.vectors_lockf = np.ones(vocab_size, dtype=np.float32)\n",
    "\n",
    "# Load the pre-trained models embeddings\n",
    "# note: if a word doesn't exist in the pre-trained vocabulary then it is left as is in the original model\n",
    "finetuned.wv.intersect_word2vec_format(pretrained_input, binary=False, lockf=1.0)\n",
    "total_examples = finetuned.corpus_count\n",
    "\n",
    "# Finally Finetuning\n",
    "finetuned.train(sentences, total_examples=total_examples, epochs= finetuned.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f277d5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T11:14:29.578336Z",
     "iopub.status.busy": "2025-05-27T11:14:29.578037Z",
     "iopub.status.idle": "2025-05-27T11:14:29.591514Z",
     "shell.execute_reply": "2025-05-27T11:14:29.590303Z"
    },
    "papermill": {
     "duration": 0.019442,
     "end_time": "2025-05-27T11:14:29.593079",
     "exception": false,
     "start_time": "2025-05-27T11:14:29.573637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "दलाल: [('दलाली', 0.5879755616188049), ('ठग', 0.5297701954841614), ('माफिया', 0.43256866931915283), ('भुमाफिया', 0.42711764574050903), ('फटाह', 0.41509851813316345), ('ठग्ने', 0.40759074687957764), ('लुटेर', 0.39497095346450806), ('धन्दा', 0.389771968126297), ('घुसखोरी', 0.38749760389328003), ('लुट्ने', 0.3824755847454071)]\n",
      "मुजि: [('माचिक्ने', 0.9070309400558472), ('नालाएक', 0.8940120339393616), ('मुँजी', 0.89377361536026), ('लाडो', 0.8901323676109314), ('dig', 0.8819910883903503), ('नभुक', 0.8801674842834473), ('रन्डि', 0.8777561783790588), ('पुती', 0.8700353503227234), ('चिक्ने', 0.8696476221084595), ('10', 0.8682755827903748)]\n",
      "रन्डि: [('चिक्ने', 0.9650057554244995), ('रन्दि', 0.9624672532081604), ('मुँजी', 0.9508404731750488), ('मादरचोद', 0.9497822523117065), ('जिउदै', 0.949225127696991), ('माचिक्ने', 0.948803186416626), ('राडि', 0.9486873149871826), ('सिदै', 0.9470410346984863), ('बिस्वराज', 0.9460260272026062), ('मजी', 0.9448207020759583)]\n",
      "चिक्ने: [('जिउदै', 0.9845611453056335), ('मजी', 0.9817609190940857), ('रण्डि', 0.9803503751754761), ('मादरचोद', 0.9797797203063965), ('हिँड्छस्', 0.9788041114807129), ('झ्याक्ने', 0.9786776900291443), ('जाठो', 0.978526771068573), ('हरामि', 0.978492021560669), ('बेस्यालय', 0.9784644246101379), ('रन्दि', 0.9784094095230103)]\n",
      "ठोक्ने: [('ठोकेर', 0.6535754799842834), ('हानेर', 0.5499934554100037), ('हान्नु', 0.5343524217605591), ('हान्ने', 0.5248708724975586), ('हान्दा', 0.4993160367012024), ('ठोक्न', 0.4931190311908722), ('भाँच्नु', 0.48692771792411804), ('बेस्सरी', 0.47289198637008667), ('हान्छु', 0.47054538130760193), ('पुच्छर', 0.4677177369594574)]\n",
      "बलात्कारी: [('अपराधी', 0.6828131079673767), ('हत्यारा', 0.649965763092041), ('दोषी', 0.564765989780426), ('भ्रष्टाचारी', 0.5586321353912354), ('अपराधि', 0.5484249591827393), ('बलात्कार', 0.5389809012413025), ('फाँसी', 0.5234779119491577), ('निर्दोष', 0.5146484971046448), ('बलत्कारी', 0.5038480162620544), ('बलत्कार', 0.5000072121620178)]\n",
      "माचिक्ने: [('लाडो', 0.9704408049583435), ('मादरजात', 0.9648088812828064), ('मुँजी', 0.9589866995811462), ('पुती', 0.9587032198905945), ('हरूले', 0.9531390070915222), ('चिक्ने', 0.9517862200737), ('रन्दि', 0.9517523646354675), ('हरूलाई', 0.9503706693649292), ('रन्डि', 0.948803186416626), ('राडि', 0.9486405849456787)]\n",
      "Similarity between ठोक and हान्नु: 0.2937004566192627\n"
     ]
    }
   ],
   "source": [
    "print(f\"दलाल: {finetuned.wv.most_similar('दलाल')}\")\n",
    "print(f\"मुजि: {finetuned.wv.most_similar('मुजि')}\")\n",
    "print(f\"रन्डि: {finetuned.wv.most_similar('रन्डि')}\")\n",
    "print(f\"चिक्ने: {finetuned.wv.most_similar('चिक्ने')}\")\n",
    "print(f\"ठोक्ने: {finetuned.wv.most_similar('ठोक्ने')}\")\n",
    "print(f\"बलात्कारी: {finetuned.wv.most_similar('बलात्कारी')}\")\n",
    "print(f\"माचिक्ने: {finetuned.wv.most_similar('माचिक्ने')}\")\n",
    "print(f\"Similarity between ठोक and हान्नु: {finetuned.wv.similarity('ठोक', 'हान्नु')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3560565b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T11:14:29.601617Z",
     "iopub.status.busy": "2025-05-27T11:14:29.601299Z",
     "iopub.status.idle": "2025-05-27T11:14:30.080719Z",
     "shell.execute_reply": "2025-05-27T11:14:30.079908Z"
    },
    "papermill": {
     "duration": 0.485339,
     "end_time": "2025-05-27T11:14:30.082250",
     "exception": false,
     "start_time": "2025-05-27T11:14:29.596911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "finetuned.wv.save_word2vec_format(os.path.join(finetuned_output, 'finetuned.txt'), binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7bcdc9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-27T11:14:30.090904Z",
     "iopub.status.busy": "2025-05-27T11:14:30.090533Z",
     "iopub.status.idle": "2025-05-27T11:14:30.506380Z",
     "shell.execute_reply": "2025-05-27T11:14:30.505199Z"
    },
    "papermill": {
     "duration": 0.421892,
     "end_time": "2025-05-27T11:14:30.507895",
     "exception": true,
     "start_time": "2025-05-27T11:14:30.086003",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "दलाल: [('दलालहरू', 0.6451959013938904), ('दलाली', 0.5998064875602722), ('बिचौलिया', 0.5902517437934875), ('पुँजीपति', 0.5644993782043457), ('ठग', 0.5342469215393066), ('एजेन्ट', 0.5191587805747986), ('पूँजीपति', 0.5182876586914062), ('नोकरशाही', 0.5007683634757996), ('कारोबारी', 0.4855310916900635), ('गिरोह', 0.4851357042789459)]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Key 'मुजि' not present in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/2121980902.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# keeping this at last as this will raise Exception and stop the script. So that all the models are saved before the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"दलाल: {pretrained.most_similar('दलाल')}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"मुजि: {pretrained.most_similar('मुजि')}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"रन्डि: {pretrained.most_similar('रन्डि')}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"चिक्ने: {pretrained.most_similar('चिक्ने')}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0;31m# compute the weighted average of all keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mean_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_normalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_normalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m         all_keys = [\n\u001b[1;32m    843\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_index_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_mean_vector\u001b[0;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mtotal_weight\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present in vocabulary\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtotal_weight\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'मुजि' not present in vocabulary\""
     ]
    }
   ],
   "source": [
    "# keeping this at last as this will raise Exception and stop the script. So that all the models are saved before the exception\n",
    "print(f\"दलाल: {pretrained.most_similar('दलाल')}\")\n",
    "print(f\"मुजि: {pretrained.most_similar('मुजि')}\")\n",
    "print(f\"रन्डि: {pretrained.most_similar('रन्डि')}\")\n",
    "print(f\"चिक्ने: {pretrained.most_similar('चिक्ने')}\")\n",
    "print(f\"ठोक्ने: {pretrained.most_similar('ठोक्ने')}\")\n",
    "print(f\"बलात्कारी: {pretrained.most_similar('बलात्कारी')}\")\n",
    "print(f\"माचिक्ने: {pretrained.most_similar('माचिक्ने')}\")\n",
    "print(f\"Similarity between ठोक and हान्नु: {pretrained.similarity('ठोक', 'हान्नु')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0110804f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "As observed the model doesn't have word vectors for profane word, which is expected as the model was trained on new sources and wikipedia."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7520078,
     "sourceId": 11969055,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7520235,
     "sourceId": 11960000,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 355.312407,
   "end_time": "2025-05-27T11:14:33.262852",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-27T11:08:37.950445",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
